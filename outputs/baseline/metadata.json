{
  "timestamp": 1760888838.5850458,
  "run": "baseline",
  "config": {
    "model": {
      "name": "Qwen/Qwen2-VL-2B-Instruct",
      "revision": null,
      "dtype": "bfloat16",
      "device": "cuda:0",
      "attn_implementation": null,
      "max_sequence_length": 4096,
      "adapter_target": "svlm.model_adapter.Qwen2VLAdapter",
      "adapter_kwargs": {
        "model_name": "Qwen/Qwen2-VL-2B-Instruct",
        "torch_dtype": "bfloat16",
        "attn_implementation": null
      },
      "gpu_id": 0
    },
    "data": {
      "name": "POPE",
      "subset": "adversarial",
      "split": "test",
      "image_column": "image",
      "text_column": "question",
      "reference_column": "answer",
      "limit": 100,
      "shuffle": false,
      "seed": 42,
      "data_path": "/data/coco",
      "image_root": "val2017",
      "annotation_path": "annotations/captions_val2017.json",
      "hf_repo": "lmms-lab/POPE",
      "hf_subset": "default",
      "hf_revision": "adversarial",
      "hf_categories": "adversarial"
    },
    "method": {
      "use_erw": true,
      "use_pva": true,
      "use_ven": true,
      "lambda_": 0.9,
      "beta": 0.9,
      "alpha": 0.6,
      "ven_eps": 1e-05
    },
    "decoding": {
      "max_new_tokens": 64,
      "temperature": 0.7,
      "top_p": 0.9,
      "top_k": null,
      "repetition_penalty": 1.0,
      "stop_words": []
    },
    "evaluation": {
      "pope": true,
      "coco_chair": true,
      "cococider": false,
      "refcoco_plus": false
    },
    "run": {
      "run_name": "baseline",
      "output_dir": "/home/junesang/svlm/outputs/baseline",
      "metadata_filename": "metadata.json",
      "save_generations": true,
      "resume_from": null,
      "seed": 42
    }
  },
  "results": [
    {
      "prompt": "Is there a snowboard in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 0,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 21.5,
          "min_logit": -8.375
        },
        {
          "step": 1,
          "max_logit": 26.5,
          "min_logit": -4.5625
        },
        {
          "step": 2,
          "max_logit": 21.375,
          "min_logit": -11.0625
        },
        {
          "step": 3,
          "max_logit": 28.875,
          "min_logit": -9.125
        },
        {
          "step": 4,
          "max_logit": 25.75,
          "min_logit": -10.0625
        },
        {
          "step": 5,
          "max_logit": 18.0,
          "min_logit": -18.25
        },
        {
          "step": 6,
          "max_logit": 22.875,
          "min_logit": -14.1875
        },
        {
          "step": 7,
          "max_logit": 19.5,
          "min_logit": -14.875
        },
        {
          "step": 8,
          "max_logit": 27.25,
          "min_logit": -11.0625
        },
        {
          "step": 9,
          "max_logit": 18.75,
          "min_logit": -16.875
        },
        {
          "step": 10,
          "max_logit": 23.0,
          "min_logit": -8.75
        },
        {
          "step": 11,
          "max_logit": 18.0,
          "min_logit": -13.1875
        },
        {
          "step": 12,
          "max_logit": 15.5625,
          "min_logit": -15.875
        },
        {
          "step": 13,
          "max_logit": 19.0,
          "min_logit": -13.875
        },
        {
          "step": 14,
          "max_logit": 13.8125,
          "min_logit": -18.25
        },
        {
          "step": 15,
          "max_logit": 21.375,
          "min_logit": -10.5
        },
        {
          "step": 16,
          "max_logit": 18.75,
          "min_logit": -15.3125
        },
        {
          "step": 17,
          "max_logit": 24.375,
          "min_logit": -14.3125
        },
        {
          "step": 18,
          "max_logit": 20.625,
          "min_logit": -13.4375
        },
        {
          "step": 19,
          "max_logit": 24.25,
          "min_logit": -12.5625
        },
        {
          "step": 20,
          "max_logit": 15.875,
          "min_logit": -17.75
        },
        {
          "step": 21,
          "max_logit": 18.625,
          "min_logit": -16.875
        },
        {
          "step": 22,
          "max_logit": 24.0,
          "min_logit": -9.6875
        }
      ],
      "raw_output": "Yes, there is a snowboard in the image. The person is riding a snowboard down the snowy slope.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        11794,
        2482,
        304,
        279,
        2168,
        13,
        576,
        1697,
        374,
        19837,
        264,
        11794,
        2482,
        1495,
        279,
        89773,
        30232,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a backpack in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 1,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.875,
          "min_logit": -10.25
        },
        {
          "step": 1,
          "max_logit": 29.125,
          "min_logit": -9.375
        },
        {
          "step": 2,
          "max_logit": 25.75,
          "min_logit": -12.0
        },
        {
          "step": 3,
          "max_logit": 19.25,
          "min_logit": -15.5
        },
        {
          "step": 4,
          "max_logit": 23.875,
          "min_logit": -11.9375
        },
        {
          "step": 5,
          "max_logit": 22.875,
          "min_logit": -10.5625
        },
        {
          "step": 6,
          "max_logit": 19.625,
          "min_logit": -15.5625
        },
        {
          "step": 7,
          "max_logit": 25.0,
          "min_logit": -6.65625
        },
        {
          "step": 8,
          "max_logit": 24.25,
          "min_logit": -10.9375
        },
        {
          "step": 9,
          "max_logit": 16.5,
          "min_logit": -16.625
        },
        {
          "step": 10,
          "max_logit": 19.25,
          "min_logit": -11.6875
        },
        {
          "step": 11,
          "max_logit": 24.5,
          "min_logit": -6.34375
        }
      ],
      "raw_output": "There is no existence of a backpack in the image description.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        33136,
        304,
        279,
        2168,
        4008,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a person in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 2,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.375,
          "min_logit": -7.75
        },
        {
          "step": 1,
          "max_logit": 26.875,
          "min_logit": -9.75
        },
        {
          "step": 2,
          "max_logit": 22.125,
          "min_logit": -9.5625
        },
        {
          "step": 3,
          "max_logit": 14.875,
          "min_logit": -16.75
        },
        {
          "step": 4,
          "max_logit": 19.5,
          "min_logit": -12.1875
        },
        {
          "step": 5,
          "max_logit": 25.5,
          "min_logit": -9.25
        },
        {
          "step": 6,
          "max_logit": 18.125,
          "min_logit": -15.5625
        },
        {
          "step": 7,
          "max_logit": 20.875,
          "min_logit": -9.5625
        }
      ],
      "raw_output": "There is a person in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        264,
        1697,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a car in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 3,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.0,
          "min_logit": -9.125
        },
        {
          "step": 1,
          "max_logit": 28.75,
          "min_logit": -9.875
        },
        {
          "step": 2,
          "max_logit": 25.5,
          "min_logit": -11.875
        },
        {
          "step": 3,
          "max_logit": 20.125,
          "min_logit": -15.6875
        },
        {
          "step": 4,
          "max_logit": 23.625,
          "min_logit": -12.3125
        },
        {
          "step": 5,
          "max_logit": 22.75,
          "min_logit": -11.6875
        },
        {
          "step": 6,
          "max_logit": 18.625,
          "min_logit": -15.375
        },
        {
          "step": 7,
          "max_logit": 23.875,
          "min_logit": -7.75
        },
        {
          "step": 8,
          "max_logit": 24.25,
          "min_logit": -10.5625
        },
        {
          "step": 9,
          "max_logit": 16.25,
          "min_logit": -17.0
        },
        {
          "step": 10,
          "max_logit": 19.25,
          "min_logit": -11.375
        }
      ],
      "raw_output": "There is no existence of a car in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        1803,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a skis in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 4,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 22.125,
          "min_logit": -8.0625
        },
        {
          "step": 1,
          "max_logit": 26.375,
          "min_logit": -8.5
        },
        {
          "step": 2,
          "max_logit": 17.625,
          "min_logit": -13.125
        },
        {
          "step": 3,
          "max_logit": 17.25,
          "min_logit": -14.9375
        },
        {
          "step": 4,
          "max_logit": 27.125,
          "min_logit": -12.125
        },
        {
          "step": 5,
          "max_logit": 22.0,
          "min_logit": -10.8125
        },
        {
          "step": 6,
          "max_logit": 26.875,
          "min_logit": -10.0
        },
        {
          "step": 7,
          "max_logit": 19.25,
          "min_logit": -17.0
        },
        {
          "step": 8,
          "max_logit": 24.25,
          "min_logit": -6.0
        }
      ],
      "raw_output": "There are no skis in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        525,
        902,
        1901,
        285,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a dog in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 5,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.0,
          "min_logit": -9.125
        },
        {
          "step": 1,
          "max_logit": 29.0,
          "min_logit": -9.6875
        },
        {
          "step": 2,
          "max_logit": 25.875,
          "min_logit": -11.25
        },
        {
          "step": 3,
          "max_logit": 20.0,
          "min_logit": -15.4375
        },
        {
          "step": 4,
          "max_logit": 23.625,
          "min_logit": -12.25
        },
        {
          "step": 5,
          "max_logit": 23.5,
          "min_logit": -10.625
        },
        {
          "step": 6,
          "max_logit": 19.25,
          "min_logit": -15.625
        },
        {
          "step": 7,
          "max_logit": 23.625,
          "min_logit": -7.53125
        },
        {
          "step": 8,
          "max_logit": 24.625,
          "min_logit": -11.3125
        },
        {
          "step": 9,
          "max_logit": 16.0,
          "min_logit": -16.75
        },
        {
          "step": 10,
          "max_logit": 19.125,
          "min_logit": -11.5
        }
      ],
      "raw_output": "There is no existence of a dog in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        5562,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a truck in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 6,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.375,
          "min_logit": -8.5625
        },
        {
          "step": 1,
          "max_logit": 26.875,
          "min_logit": -5.8125
        },
        {
          "step": 2,
          "max_logit": 23.0,
          "min_logit": -9.8125
        },
        {
          "step": 3,
          "max_logit": 29.375,
          "min_logit": -8.9375
        },
        {
          "step": 4,
          "max_logit": 25.75,
          "min_logit": -9.0
        },
        {
          "step": 5,
          "max_logit": 17.25,
          "min_logit": -17.125
        },
        {
          "step": 6,
          "max_logit": 21.375,
          "min_logit": -13.0
        },
        {
          "step": 7,
          "max_logit": 26.625,
          "min_logit": -9.8125
        },
        {
          "step": 8,
          "max_logit": 19.25,
          "min_logit": -15.125
        },
        {
          "step": 9,
          "max_logit": 23.625,
          "min_logit": -7.1875
        }
      ],
      "raw_output": "Yes, there is a truck in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        10855,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a car in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 7,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.375,
          "min_logit": -8.5625
        },
        {
          "step": 1,
          "max_logit": 26.75,
          "min_logit": -5.09375
        },
        {
          "step": 2,
          "max_logit": 22.5,
          "min_logit": -10.375
        },
        {
          "step": 3,
          "max_logit": 29.25,
          "min_logit": -9.0
        },
        {
          "step": 4,
          "max_logit": 25.25,
          "min_logit": -9.8125
        },
        {
          "step": 5,
          "max_logit": 16.375,
          "min_logit": -17.625
        },
        {
          "step": 6,
          "max_logit": 21.125,
          "min_logit": -11.9375
        },
        {
          "step": 7,
          "max_logit": 26.25,
          "min_logit": -9.875
        },
        {
          "step": 8,
          "max_logit": 18.625,
          "min_logit": -15.0625
        },
        {
          "step": 9,
          "max_logit": 23.5,
          "min_logit": -6.59375
        }
      ],
      "raw_output": "Yes, there is a car in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        1803,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a person in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 8,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 24.125,
          "min_logit": -8.125
        },
        {
          "step": 1,
          "max_logit": 26.75,
          "min_logit": -4.625
        },
        {
          "step": 2,
          "max_logit": 21.875,
          "min_logit": -10.9375
        },
        {
          "step": 3,
          "max_logit": 28.125,
          "min_logit": -7.71875
        },
        {
          "step": 4,
          "max_logit": 24.25,
          "min_logit": -9.5
        },
        {
          "step": 5,
          "max_logit": 16.5,
          "min_logit": -16.375
        },
        {
          "step": 6,
          "max_logit": 20.0,
          "min_logit": -14.125
        },
        {
          "step": 7,
          "max_logit": 26.375,
          "min_logit": -8.9375
        },
        {
          "step": 8,
          "max_logit": 19.375,
          "min_logit": -15.1875
        },
        {
          "step": 9,
          "max_logit": 21.75,
          "min_logit": -9.75
        }
      ],
      "raw_output": "Yes, there is a person in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        1697,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a dining table in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 9,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 26.125,
          "min_logit": -10.25
        },
        {
          "step": 1,
          "max_logit": 28.875,
          "min_logit": -9.8125
        },
        {
          "step": 2,
          "max_logit": 25.875,
          "min_logit": -10.9375
        },
        {
          "step": 3,
          "max_logit": 21.625,
          "min_logit": -14.1875
        },
        {
          "step": 4,
          "max_logit": 23.0,
          "min_logit": -12.3125
        },
        {
          "step": 5,
          "max_logit": 22.75,
          "min_logit": -9.3125
        },
        {
          "step": 6,
          "max_logit": 20.125,
          "min_logit": -14.1875
        },
        {
          "step": 7,
          "max_logit": 26.0,
          "min_logit": -14.9375
        },
        {
          "step": 8,
          "max_logit": 25.75,
          "min_logit": -7.21875
        },
        {
          "step": 9,
          "max_logit": 25.25,
          "min_logit": -9.5625
        },
        {
          "step": 10,
          "max_logit": 16.875,
          "min_logit": -16.0
        },
        {
          "step": 11,
          "max_logit": 18.75,
          "min_logit": -11.875
        },
        {
          "step": 12,
          "max_logit": 21.75,
          "min_logit": -11.3125
        }
      ],
      "raw_output": "There is no existence of a dining table in the image information.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        17914,
        1965,
        304,
        279,
        2168,
        1995,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there an umbrella in the imange?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 10,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 22.375,
          "min_logit": -9.6875
        },
        {
          "step": 1,
          "max_logit": 26.75,
          "min_logit": -5.375
        },
        {
          "step": 2,
          "max_logit": 24.125,
          "min_logit": -9.875
        },
        {
          "step": 3,
          "max_logit": 30.0,
          "min_logit": -10.75
        },
        {
          "step": 4,
          "max_logit": 27.125,
          "min_logit": -7.96875
        },
        {
          "step": 5,
          "max_logit": 21.875,
          "min_logit": -18.375
        },
        {
          "step": 6,
          "max_logit": 23.25,
          "min_logit": -10.8125
        },
        {
          "step": 7,
          "max_logit": 29.125,
          "min_logit": -8.3125
        },
        {
          "step": 8,
          "max_logit": 23.375,
          "min_logit": -15.6875
        },
        {
          "step": 9,
          "max_logit": 24.75,
          "min_logit": -9.75
        }
      ],
      "raw_output": "Yes, there is an umbrella in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        458,
        47898,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a handbag in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 11,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.375,
          "min_logit": -10.75
        },
        {
          "step": 1,
          "max_logit": 29.375,
          "min_logit": -9.5
        },
        {
          "step": 2,
          "max_logit": 26.125,
          "min_logit": -11.5
        },
        {
          "step": 3,
          "max_logit": 20.875,
          "min_logit": -14.8125
        },
        {
          "step": 4,
          "max_logit": 24.0,
          "min_logit": -11.625
        },
        {
          "step": 5,
          "max_logit": 24.5,
          "min_logit": -9.6875
        },
        {
          "step": 6,
          "max_logit": 21.875,
          "min_logit": -15.125
        },
        {
          "step": 7,
          "max_logit": 27.25,
          "min_logit": -14.5
        },
        {
          "step": 8,
          "max_logit": 25.125,
          "min_logit": -6.96875
        },
        {
          "step": 9,
          "max_logit": 24.75,
          "min_logit": -10.375
        },
        {
          "step": 10,
          "max_logit": 17.0,
          "min_logit": -16.0
        },
        {
          "step": 11,
          "max_logit": 19.0,
          "min_logit": -12.1875
        },
        {
          "step": 12,
          "max_logit": 24.25,
          "min_logit": -6.59375
        }
      ],
      "raw_output": "There is no existence of a handbag in the image description.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        1424,
        21250,
        304,
        279,
        2168,
        4008,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a person in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 12,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 22.5,
          "min_logit": -9.8125
        },
        {
          "step": 1,
          "max_logit": 26.5,
          "min_logit": -9.3125
        },
        {
          "step": 2,
          "max_logit": 21.375,
          "min_logit": -10.75
        },
        {
          "step": 3,
          "max_logit": 18.875,
          "min_logit": -15.5625
        },
        {
          "step": 4,
          "max_logit": 24.0,
          "min_logit": -11.5625
        },
        {
          "step": 5,
          "max_logit": 21.625,
          "min_logit": -11.875
        },
        {
          "step": 6,
          "max_logit": 18.0,
          "min_logit": -15.4375
        },
        {
          "step": 7,
          "max_logit": 21.75,
          "min_logit": -9.875
        },
        {
          "step": 8,
          "max_logit": 22.75,
          "min_logit": -11.4375
        },
        {
          "step": 9,
          "max_logit": 15.125,
          "min_logit": -17.0
        },
        {
          "step": 10,
          "max_logit": 19.25,
          "min_logit": -11.625
        }
      ],
      "raw_output": "There is no existence of a person in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        1697,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a dining table in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 13,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 24.5,
          "min_logit": -10.5625
        },
        {
          "step": 1,
          "max_logit": 28.625,
          "min_logit": -10.125
        },
        {
          "step": 2,
          "max_logit": 24.875,
          "min_logit": -10.875
        },
        {
          "step": 3,
          "max_logit": 21.75,
          "min_logit": -13.9375
        },
        {
          "step": 4,
          "max_logit": 23.75,
          "min_logit": -11.4375
        },
        {
          "step": 5,
          "max_logit": 21.625,
          "min_logit": -9.6875
        },
        {
          "step": 6,
          "max_logit": 19.75,
          "min_logit": -15.0
        },
        {
          "step": 7,
          "max_logit": 25.125,
          "min_logit": -14.75
        },
        {
          "step": 8,
          "max_logit": 25.5,
          "min_logit": -7.40625
        },
        {
          "step": 9,
          "max_logit": 24.875,
          "min_logit": -10.0
        },
        {
          "step": 10,
          "max_logit": 16.375,
          "min_logit": -16.5
        },
        {
          "step": 11,
          "max_logit": 18.875,
          "min_logit": -11.75
        }
      ],
      "raw_output": "There is no existence of a dining table in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        17914,
        1965,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a bicycle in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 14,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.375,
          "min_logit": -8.5
        },
        {
          "step": 1,
          "max_logit": 26.375,
          "min_logit": -5.0
        },
        {
          "step": 2,
          "max_logit": 21.25,
          "min_logit": -11.4375
        },
        {
          "step": 3,
          "max_logit": 28.5,
          "min_logit": -8.5
        },
        {
          "step": 4,
          "max_logit": 24.875,
          "min_logit": -9.25
        },
        {
          "step": 5,
          "max_logit": 15.5625,
          "min_logit": -18.75
        },
        {
          "step": 6,
          "max_logit": 18.75,
          "min_logit": -13.0625
        },
        {
          "step": 7,
          "max_logit": 25.875,
          "min_logit": -10.25
        },
        {
          "step": 8,
          "max_logit": 17.5,
          "min_logit": -17.5
        },
        {
          "step": 9,
          "max_logit": 21.5,
          "min_logit": -8.25
        },
        {
          "step": 10,
          "max_logit": 17.375,
          "min_logit": -13.25
        },
        {
          "step": 11,
          "max_logit": 23.625,
          "min_logit": -14.0625
        },
        {
          "step": 12,
          "max_logit": 15.125,
          "min_logit": -16.25
        },
        {
          "step": 13,
          "max_logit": 19.25,
          "min_logit": -10.9375
        },
        {
          "step": 14,
          "max_logit": 22.125,
          "min_logit": -12.625
        },
        {
          "step": 15,
          "max_logit": 14.875,
          "min_logit": -17.75
        },
        {
          "step": 16,
          "max_logit": 22.25,
          "min_logit": -11.5
        },
        {
          "step": 17,
          "max_logit": 24.0,
          "min_logit": -9.25
        },
        {
          "step": 18,
          "max_logit": 15.375,
          "min_logit": -17.625
        },
        {
          "step": 19,
          "max_logit": 21.125,
          "min_logit": -8.75
        },
        {
          "step": 20,
          "max_logit": 19.75,
          "min_logit": -13.0
        },
        {
          "step": 21,
          "max_logit": 10.4375,
          "min_logit": -17.5
        },
        {
          "step": 22,
          "max_logit": 13.25,
          "min_logit": -16.75
        },
        {
          "step": 23,
          "max_logit": 23.125,
          "min_logit": -7.71875
        }
      ],
      "raw_output": "Yes, there is a bicycle in the image. It is parked on the side of the road near the red buses.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        34986,
        304,
        279,
        2168,
        13,
        1084,
        374,
        42235,
        389,
        279,
        3108,
        315,
        279,
        5636,
        3143,
        279,
        2518,
        33380,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a motorcycle in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 15,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.625,
          "min_logit": -10.0
        },
        {
          "step": 1,
          "max_logit": 28.125,
          "min_logit": -9.1875
        },
        {
          "step": 2,
          "max_logit": 24.375,
          "min_logit": -11.0
        },
        {
          "step": 3,
          "max_logit": 20.25,
          "min_logit": -15.0
        },
        {
          "step": 4,
          "max_logit": 23.5,
          "min_logit": -11.5625
        },
        {
          "step": 5,
          "max_logit": 22.625,
          "min_logit": -8.375
        },
        {
          "step": 6,
          "max_logit": 20.375,
          "min_logit": -15.25
        },
        {
          "step": 7,
          "max_logit": 23.5,
          "min_logit": -8.3125
        },
        {
          "step": 8,
          "max_logit": 23.875,
          "min_logit": -11.125
        },
        {
          "step": 9,
          "max_logit": 15.8125,
          "min_logit": -16.625
        },
        {
          "step": 10,
          "max_logit": 19.25,
          "min_logit": -11.5
        }
      ],
      "raw_output": "There is no existence of a motorcycle in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        34304,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a car in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 16,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 22.375,
          "min_logit": -8.6875
        },
        {
          "step": 1,
          "max_logit": 26.25,
          "min_logit": -9.4375
        },
        {
          "step": 2,
          "max_logit": 22.0,
          "min_logit": -10.0625
        },
        {
          "step": 3,
          "max_logit": 20.0,
          "min_logit": -14.5
        },
        {
          "step": 4,
          "max_logit": 23.75,
          "min_logit": -12.125
        },
        {
          "step": 5,
          "max_logit": 23.625,
          "min_logit": -9.375
        },
        {
          "step": 6,
          "max_logit": 18.875,
          "min_logit": -16.375
        },
        {
          "step": 7,
          "max_logit": 23.0,
          "min_logit": -9.0625
        },
        {
          "step": 8,
          "max_logit": 23.0,
          "min_logit": -10.875
        },
        {
          "step": 9,
          "max_logit": 15.375,
          "min_logit": -16.75
        },
        {
          "step": 10,
          "max_logit": 19.25,
          "min_logit": -11.5625
        },
        {
          "step": 11,
          "max_logit": 23.625,
          "min_logit": -6.96875
        }
      ],
      "raw_output": "There is no existence of a car in the image description.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        1803,
        304,
        279,
        2168,
        4008,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a truck in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 17,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.0,
          "min_logit": -8.375
        },
        {
          "step": 1,
          "max_logit": 26.375,
          "min_logit": -5.09375
        },
        {
          "step": 2,
          "max_logit": 21.5,
          "min_logit": -11.1875
        },
        {
          "step": 3,
          "max_logit": 28.375,
          "min_logit": -8.875
        },
        {
          "step": 4,
          "max_logit": 24.375,
          "min_logit": -9.375
        },
        {
          "step": 5,
          "max_logit": 12.625,
          "min_logit": -19.0
        },
        {
          "step": 6,
          "max_logit": 19.125,
          "min_logit": -13.3125
        },
        {
          "step": 7,
          "max_logit": 25.5,
          "min_logit": -9.625
        },
        {
          "step": 8,
          "max_logit": 17.25,
          "min_logit": -17.75
        },
        {
          "step": 9,
          "max_logit": 22.125,
          "min_logit": -8.25
        }
      ],
      "raw_output": "Yes, there is a truck in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        10855,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a person in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 18,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 21.875,
          "min_logit": -10.1875
        },
        {
          "step": 1,
          "max_logit": 26.0,
          "min_logit": -4.8125
        },
        {
          "step": 2,
          "max_logit": 20.625,
          "min_logit": -13.0625
        },
        {
          "step": 3,
          "max_logit": 27.5,
          "min_logit": -8.3125
        },
        {
          "step": 4,
          "max_logit": 22.625,
          "min_logit": -10.125
        },
        {
          "step": 5,
          "max_logit": 16.0,
          "min_logit": -17.25
        },
        {
          "step": 6,
          "max_logit": 18.125,
          "min_logit": -13.375
        },
        {
          "step": 7,
          "max_logit": 25.5,
          "min_logit": -9.5625
        },
        {
          "step": 8,
          "max_logit": 17.5,
          "min_logit": -15.5625
        },
        {
          "step": 9,
          "max_logit": 20.625,
          "min_logit": -10.75
        }
      ],
      "raw_output": "Yes, there is a person in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        1697,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a dining table in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 19,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.375,
          "min_logit": -10.1875
        },
        {
          "step": 1,
          "max_logit": 29.0,
          "min_logit": -10.3125
        },
        {
          "step": 2,
          "max_logit": 25.625,
          "min_logit": -10.4375
        },
        {
          "step": 3,
          "max_logit": 22.0,
          "min_logit": -14.0
        },
        {
          "step": 4,
          "max_logit": 23.625,
          "min_logit": -11.8125
        },
        {
          "step": 5,
          "max_logit": 21.5,
          "min_logit": -9.5
        },
        {
          "step": 6,
          "max_logit": 20.125,
          "min_logit": -14.75
        },
        {
          "step": 7,
          "max_logit": 25.25,
          "min_logit": -15.125
        },
        {
          "step": 8,
          "max_logit": 25.75,
          "min_logit": -7.40625
        },
        {
          "step": 9,
          "max_logit": 25.125,
          "min_logit": -9.8125
        },
        {
          "step": 10,
          "max_logit": 16.625,
          "min_logit": -16.5
        },
        {
          "step": 11,
          "max_logit": 18.75,
          "min_logit": -11.6875
        }
      ],
      "raw_output": "There is no existence of a dining table in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        17914,
        1965,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a potted plant in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 20,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 24.125,
          "min_logit": -9.625
        },
        {
          "step": 1,
          "max_logit": 28.375,
          "min_logit": -10.25
        },
        {
          "step": 2,
          "max_logit": 24.25,
          "min_logit": -10.1875
        },
        {
          "step": 3,
          "max_logit": 21.75,
          "min_logit": -14.1875
        },
        {
          "step": 4,
          "max_logit": 24.375,
          "min_logit": -11.9375
        },
        {
          "step": 5,
          "max_logit": 21.75,
          "min_logit": -11.0
        },
        {
          "step": 6,
          "max_logit": 19.875,
          "min_logit": -14.5
        },
        {
          "step": 7,
          "max_logit": 28.25,
          "min_logit": -15.5625
        },
        {
          "step": 8,
          "max_logit": 22.75,
          "min_logit": -14.875
        },
        {
          "step": 9,
          "max_logit": 24.5,
          "min_logit": -7.6875
        },
        {
          "step": 10,
          "max_logit": 24.125,
          "min_logit": -10.125
        },
        {
          "step": 11,
          "max_logit": 16.375,
          "min_logit": -16.25
        },
        {
          "step": 12,
          "max_logit": 19.125,
          "min_logit": -11.6875
        }
      ],
      "raw_output": "There is no existence of a potted plant in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        281,
        15521,
        6008,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a vase in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 21,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 26.625,
          "min_logit": -10.0625
        },
        {
          "step": 1,
          "max_logit": 29.375,
          "min_logit": -10.5
        },
        {
          "step": 2,
          "max_logit": 26.625,
          "min_logit": -10.875
        },
        {
          "step": 3,
          "max_logit": 22.375,
          "min_logit": -14.6875
        },
        {
          "step": 4,
          "max_logit": 24.125,
          "min_logit": -11.1875
        },
        {
          "step": 5,
          "max_logit": 21.75,
          "min_logit": -9.125
        },
        {
          "step": 6,
          "max_logit": 20.125,
          "min_logit": -13.8125
        },
        {
          "step": 7,
          "max_logit": 25.375,
          "min_logit": -7.53125
        },
        {
          "step": 8,
          "max_logit": 25.125,
          "min_logit": -9.5625
        },
        {
          "step": 9,
          "max_logit": 17.0,
          "min_logit": -15.9375
        },
        {
          "step": 10,
          "max_logit": 19.25,
          "min_logit": -11.1875
        },
        {
          "step": 11,
          "max_logit": 24.375,
          "min_logit": -6.59375
        }
      ],
      "raw_output": "There is no existence of a vase in the image description.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        92384,
        304,
        279,
        2168,
        4008,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a car in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 22,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.0,
          "min_logit": -9.1875
        },
        {
          "step": 1,
          "max_logit": 27.25,
          "min_logit": -9.25
        },
        {
          "step": 2,
          "max_logit": 22.625,
          "min_logit": -11.4375
        },
        {
          "step": 3,
          "max_logit": 19.875,
          "min_logit": -14.6875
        },
        {
          "step": 4,
          "max_logit": 23.5,
          "min_logit": -12.125
        },
        {
          "step": 5,
          "max_logit": 23.375,
          "min_logit": -10.125
        },
        {
          "step": 6,
          "max_logit": 19.75,
          "min_logit": -16.0
        },
        {
          "step": 7,
          "max_logit": 22.5,
          "min_logit": -8.6875
        },
        {
          "step": 8,
          "max_logit": 23.25,
          "min_logit": -10.8125
        },
        {
          "step": 9,
          "max_logit": 15.625,
          "min_logit": -17.0
        },
        {
          "step": 10,
          "max_logit": 19.375,
          "min_logit": -11.4375
        },
        {
          "step": 11,
          "max_logit": 23.375,
          "min_logit": -6.84375
        }
      ],
      "raw_output": "There is no existence of a car in the image description.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        1803,
        304,
        279,
        2168,
        4008,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a truck in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 23,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.125,
          "min_logit": -9.4375
        },
        {
          "step": 1,
          "max_logit": 28.5,
          "min_logit": -9.5
        },
        {
          "step": 2,
          "max_logit": 25.375,
          "min_logit": -10.1875
        },
        {
          "step": 3,
          "max_logit": 20.5,
          "min_logit": -15.75
        },
        {
          "step": 4,
          "max_logit": 23.125,
          "min_logit": -11.875
        },
        {
          "step": 5,
          "max_logit": 23.0,
          "min_logit": -9.3125
        },
        {
          "step": 6,
          "max_logit": 18.0,
          "min_logit": -16.25
        },
        {
          "step": 7,
          "max_logit": 23.5,
          "min_logit": -8.9375
        },
        {
          "step": 8,
          "max_logit": 24.0,
          "min_logit": -10.5
        },
        {
          "step": 9,
          "max_logit": 16.125,
          "min_logit": -16.625
        },
        {
          "step": 10,
          "max_logit": 19.5,
          "min_logit": -11.25
        },
        {
          "step": 11,
          "max_logit": 23.75,
          "min_logit": -6.65625
        }
      ],
      "raw_output": "There is no existence of a truck in the image description.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        10855,
        304,
        279,
        2168,
        4008,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a traffic light in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 24,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.125,
          "min_logit": -9.5
        },
        {
          "step": 1,
          "max_logit": 26.625,
          "min_logit": -4.8125
        },
        {
          "step": 2,
          "max_logit": 22.125,
          "min_logit": -12.3125
        },
        {
          "step": 3,
          "max_logit": 29.375,
          "min_logit": -9.625
        },
        {
          "step": 4,
          "max_logit": 26.0,
          "min_logit": -9.1875
        },
        {
          "step": 5,
          "max_logit": 18.25,
          "min_logit": -18.125
        },
        {
          "step": 6,
          "max_logit": 23.0,
          "min_logit": -16.125
        },
        {
          "step": 7,
          "max_logit": 20.5,
          "min_logit": -12.75
        },
        {
          "step": 8,
          "max_logit": 26.375,
          "min_logit": -9.875
        },
        {
          "step": 9,
          "max_logit": 18.75,
          "min_logit": -15.5
        },
        {
          "step": 10,
          "max_logit": 22.875,
          "min_logit": -8.25
        }
      ],
      "raw_output": "Yes, there is a traffic light in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        9442,
        3100,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a bus in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 25,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.75,
          "min_logit": -9.875
        },
        {
          "step": 1,
          "max_logit": 28.0,
          "min_logit": -9.25
        },
        {
          "step": 2,
          "max_logit": 23.375,
          "min_logit": -11.3125
        },
        {
          "step": 3,
          "max_logit": 19.875,
          "min_logit": -14.875
        },
        {
          "step": 4,
          "max_logit": 23.25,
          "min_logit": -12.125
        },
        {
          "step": 5,
          "max_logit": 22.75,
          "min_logit": -10.8125
        },
        {
          "step": 6,
          "max_logit": 19.0,
          "min_logit": -17.125
        },
        {
          "step": 7,
          "max_logit": 23.75,
          "min_logit": -8.0
        },
        {
          "step": 8,
          "max_logit": 24.0,
          "min_logit": -10.4375
        },
        {
          "step": 9,
          "max_logit": 16.375,
          "min_logit": -16.125
        },
        {
          "step": 10,
          "max_logit": 19.125,
          "min_logit": -11.8125
        }
      ],
      "raw_output": "There is no existence of a bus in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        5828,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a person in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 26,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 22.875,
          "min_logit": -9.3125
        },
        {
          "step": 1,
          "max_logit": 25.625,
          "min_logit": -9.875
        },
        {
          "step": 2,
          "max_logit": 19.875,
          "min_logit": -11.125
        },
        {
          "step": 3,
          "max_logit": 18.375,
          "min_logit": -15.6875
        },
        {
          "step": 4,
          "max_logit": 23.5,
          "min_logit": -11.625
        },
        {
          "step": 5,
          "max_logit": 20.75,
          "min_logit": -12.3125
        },
        {
          "step": 6,
          "max_logit": 17.875,
          "min_logit": -16.125
        },
        {
          "step": 7,
          "max_logit": 21.625,
          "min_logit": -10.0
        },
        {
          "step": 8,
          "max_logit": 22.75,
          "min_logit": -10.875
        },
        {
          "step": 9,
          "max_logit": 15.375,
          "min_logit": -16.125
        },
        {
          "step": 10,
          "max_logit": 19.5,
          "min_logit": -11.5625
        }
      ],
      "raw_output": "There is no existence of a person in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        1697,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a dining table in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 27,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.625,
          "min_logit": -9.875
        },
        {
          "step": 1,
          "max_logit": 28.625,
          "min_logit": -10.0625
        },
        {
          "step": 2,
          "max_logit": 25.25,
          "min_logit": -11.1875
        },
        {
          "step": 3,
          "max_logit": 21.625,
          "min_logit": -14.375
        },
        {
          "step": 4,
          "max_logit": 23.125,
          "min_logit": -12.25
        },
        {
          "step": 5,
          "max_logit": 22.25,
          "min_logit": -9.125
        },
        {
          "step": 6,
          "max_logit": 20.375,
          "min_logit": -14.6875
        },
        {
          "step": 7,
          "max_logit": 25.375,
          "min_logit": -15.1875
        },
        {
          "step": 8,
          "max_logit": 25.5,
          "min_logit": -7.28125
        },
        {
          "step": 9,
          "max_logit": 25.375,
          "min_logit": -9.4375
        },
        {
          "step": 10,
          "max_logit": 16.75,
          "min_logit": -16.625
        },
        {
          "step": 11,
          "max_logit": 19.125,
          "min_logit": -11.5625
        },
        {
          "step": 12,
          "max_logit": 22.125,
          "min_logit": -10.8125
        }
      ],
      "raw_output": "There is no existence of a dining table in the image information.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        17914,
        1965,
        304,
        279,
        2168,
        1995,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a car in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 28,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.125,
          "min_logit": -8.25
        },
        {
          "step": 1,
          "max_logit": 26.125,
          "min_logit": -4.625
        },
        {
          "step": 2,
          "max_logit": 21.375,
          "min_logit": -11.4375
        },
        {
          "step": 3,
          "max_logit": 28.75,
          "min_logit": -10.0
        },
        {
          "step": 4,
          "max_logit": 23.625,
          "min_logit": -9.8125
        },
        {
          "step": 5,
          "max_logit": 15.6875,
          "min_logit": -16.75
        },
        {
          "step": 6,
          "max_logit": 20.125,
          "min_logit": -12.5
        },
        {
          "step": 7,
          "max_logit": 26.75,
          "min_logit": -10.5625
        },
        {
          "step": 8,
          "max_logit": 19.125,
          "min_logit": -15.5625
        },
        {
          "step": 9,
          "max_logit": 22.75,
          "min_logit": -7.875
        }
      ],
      "raw_output": "Yes, there is a car in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        1803,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a truck in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 29,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.375,
          "min_logit": -9.4375
        },
        {
          "step": 1,
          "max_logit": 27.5,
          "min_logit": -9.0625
        },
        {
          "step": 2,
          "max_logit": 23.125,
          "min_logit": -10.1875
        },
        {
          "step": 3,
          "max_logit": 19.0,
          "min_logit": -15.1875
        },
        {
          "step": 4,
          "max_logit": 23.125,
          "min_logit": -12.375
        },
        {
          "step": 5,
          "max_logit": 22.125,
          "min_logit": -10.8125
        },
        {
          "step": 6,
          "max_logit": 18.5,
          "min_logit": -17.125
        },
        {
          "step": 7,
          "max_logit": 23.25,
          "min_logit": -8.375
        },
        {
          "step": 8,
          "max_logit": 23.625,
          "min_logit": -10.5
        },
        {
          "step": 9,
          "max_logit": 16.0,
          "min_logit": -16.375
        },
        {
          "step": 10,
          "max_logit": 19.375,
          "min_logit": -11.8125
        },
        {
          "step": 11,
          "max_logit": 24.0,
          "min_logit": -6.8125
        }
      ],
      "raw_output": "There is no existence of a truck in the image description.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        10855,
        304,
        279,
        2168,
        4008,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a dog in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 30,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.25,
          "min_logit": -8.4375
        },
        {
          "step": 1,
          "max_logit": 26.0,
          "min_logit": -4.5625
        },
        {
          "step": 2,
          "max_logit": 21.5,
          "min_logit": -9.4375
        },
        {
          "step": 3,
          "max_logit": 28.375,
          "min_logit": -8.8125
        },
        {
          "step": 4,
          "max_logit": 24.75,
          "min_logit": -9.5
        },
        {
          "step": 5,
          "max_logit": 15.25,
          "min_logit": -16.25
        },
        {
          "step": 6,
          "max_logit": 19.5,
          "min_logit": -14.0625
        },
        {
          "step": 7,
          "max_logit": 27.375,
          "min_logit": -8.9375
        },
        {
          "step": 8,
          "max_logit": 19.0,
          "min_logit": -15.8125
        },
        {
          "step": 9,
          "max_logit": 21.25,
          "min_logit": -9.75
        },
        {
          "step": 10,
          "max_logit": 18.25,
          "min_logit": -12.25
        },
        {
          "step": 11,
          "max_logit": 21.75,
          "min_logit": -13.3125
        },
        {
          "step": 12,
          "max_logit": 16.625,
          "min_logit": -15.0625
        },
        {
          "step": 13,
          "max_logit": 22.875,
          "min_logit": -15.75
        },
        {
          "step": 14,
          "max_logit": 13.3125,
          "min_logit": -17.75
        },
        {
          "step": 15,
          "max_logit": 12.625,
          "min_logit": -16.5
        },
        {
          "step": 16,
          "max_logit": 13.125,
          "min_logit": -16.5
        },
        {
          "step": 17,
          "max_logit": 24.75,
          "min_logit": -12.0
        },
        {
          "step": 18,
          "max_logit": 15.25,
          "min_logit": -13.3125
        },
        {
          "step": 19,
          "max_logit": 14.8125,
          "min_logit": -15.125
        },
        {
          "step": 20,
          "max_logit": 13.125,
          "min_logit": -15.625
        },
        {
          "step": 21,
          "max_logit": 18.375,
          "min_logit": -14.1875
        },
        {
          "step": 22,
          "max_logit": 17.125,
          "min_logit": -13.875
        },
        {
          "step": 23,
          "max_logit": 13.375,
          "min_logit": -15.75
        },
        {
          "step": 24,
          "max_logit": 18.625,
          "min_logit": -13.9375
        },
        {
          "step": 25,
          "max_logit": 22.0,
          "min_logit": -10.0625
        },
        {
          "step": 26,
          "max_logit": 15.625,
          "min_logit": -14.4375
        },
        {
          "step": 27,
          "max_logit": 19.75,
          "min_logit": -10.5625
        },
        {
          "step": 28,
          "max_logit": 29.5,
          "min_logit": -9.25
        },
        {
          "step": 29,
          "max_logit": 18.875,
          "min_logit": -14.0625
        },
        {
          "step": 30,
          "max_logit": 14.125,
          "min_logit": -17.375
        },
        {
          "step": 31,
          "max_logit": 27.875,
          "min_logit": -8.5625
        },
        {
          "step": 32,
          "max_logit": 15.25,
          "min_logit": -17.375
        },
        {
          "step": 33,
          "max_logit": 24.5,
          "min_logit": -8.9375
        }
      ],
      "raw_output": "Yes, there is a dog in the image. It appears to be a white poodle puppy with curly hair, lying on a table next to a stack of newspapers.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        5562,
        304,
        279,
        2168,
        13,
        1084,
        7952,
        311,
        387,
        264,
        4158,
        281,
        30607,
        41189,
        448,
        68103,
        6869,
        11,
        20446,
        389,
        264,
        1965,
        1790,
        311,
        264,
        5611,
        315,
        31494,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a person in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 31,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.375,
          "min_logit": -9.1875
        },
        {
          "step": 1,
          "max_logit": 28.875,
          "min_logit": -9.0
        },
        {
          "step": 2,
          "max_logit": 25.25,
          "min_logit": -10.5625
        },
        {
          "step": 3,
          "max_logit": 21.25,
          "min_logit": -15.625
        },
        {
          "step": 4,
          "max_logit": 24.375,
          "min_logit": -11.1875
        },
        {
          "step": 5,
          "max_logit": 23.75,
          "min_logit": -10.5625
        },
        {
          "step": 6,
          "max_logit": 19.75,
          "min_logit": -15.0625
        },
        {
          "step": 7,
          "max_logit": 23.375,
          "min_logit": -9.5
        },
        {
          "step": 8,
          "max_logit": 25.125,
          "min_logit": -8.375
        },
        {
          "step": 9,
          "max_logit": 16.75,
          "min_logit": -15.4375
        },
        {
          "step": 10,
          "max_logit": 19.375,
          "min_logit": -11.5
        },
        {
          "step": 11,
          "max_logit": 21.0,
          "min_logit": -11.0625
        }
      ],
      "raw_output": "There is no existence of a person in the image information.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        1697,
        304,
        279,
        2168,
        1995,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a dining table in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 32,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 21.5,
          "min_logit": -9.1875
        },
        {
          "step": 1,
          "max_logit": 26.75,
          "min_logit": -9.8125
        },
        {
          "step": 2,
          "max_logit": 22.625,
          "min_logit": -9.1875
        },
        {
          "step": 3,
          "max_logit": 17.75,
          "min_logit": -15.0
        },
        {
          "step": 4,
          "max_logit": 22.875,
          "min_logit": -12.1875
        },
        {
          "step": 5,
          "max_logit": 22.5,
          "min_logit": -9.125
        },
        {
          "step": 6,
          "max_logit": 19.5,
          "min_logit": -14.625
        },
        {
          "step": 7,
          "max_logit": 25.5,
          "min_logit": -13.8125
        },
        {
          "step": 8,
          "max_logit": 24.5,
          "min_logit": -7.46875
        },
        {
          "step": 9,
          "max_logit": 23.5,
          "min_logit": -10.8125
        },
        {
          "step": 10,
          "max_logit": 15.9375,
          "min_logit": -16.125
        },
        {
          "step": 11,
          "max_logit": 18.25,
          "min_logit": -12.625
        },
        {
          "step": 12,
          "max_logit": 23.625,
          "min_logit": -7.09375
        }
      ],
      "raw_output": "There is no existence of a dining table in the image description.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        17914,
        1965,
        304,
        279,
        2168,
        4008,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a chair in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 33,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 24.125,
          "min_logit": -8.875
        },
        {
          "step": 1,
          "max_logit": 28.375,
          "min_logit": -9.625
        },
        {
          "step": 2,
          "max_logit": 24.5,
          "min_logit": -10.5
        },
        {
          "step": 3,
          "max_logit": 21.875,
          "min_logit": -13.5625
        },
        {
          "step": 4,
          "max_logit": 23.875,
          "min_logit": -11.6875
        },
        {
          "step": 5,
          "max_logit": 24.25,
          "min_logit": -8.875
        },
        {
          "step": 6,
          "max_logit": 20.625,
          "min_logit": -15.5
        },
        {
          "step": 7,
          "max_logit": 24.5,
          "min_logit": -7.28125
        },
        {
          "step": 8,
          "max_logit": 24.75,
          "min_logit": -10.0625
        },
        {
          "step": 9,
          "max_logit": 16.375,
          "min_logit": -15.8125
        },
        {
          "step": 10,
          "max_logit": 18.75,
          "min_logit": -12.125
        }
      ],
      "raw_output": "There is no existence of a chair in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        10496,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a bed in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 34,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.25,
          "min_logit": -8.9375
        },
        {
          "step": 1,
          "max_logit": 28.0,
          "min_logit": -9.75
        },
        {
          "step": 2,
          "max_logit": 24.5,
          "min_logit": -10.5
        },
        {
          "step": 3,
          "max_logit": 19.75,
          "min_logit": -13.9375
        },
        {
          "step": 4,
          "max_logit": 23.5,
          "min_logit": -12.375
        },
        {
          "step": 5,
          "max_logit": 23.75,
          "min_logit": -9.25
        },
        {
          "step": 6,
          "max_logit": 20.0,
          "min_logit": -14.9375
        },
        {
          "step": 7,
          "max_logit": 24.375,
          "min_logit": -7.28125
        },
        {
          "step": 8,
          "max_logit": 24.875,
          "min_logit": -9.5625
        },
        {
          "step": 9,
          "max_logit": 16.625,
          "min_logit": -16.0
        },
        {
          "step": 10,
          "max_logit": 18.875,
          "min_logit": -11.9375
        },
        {
          "step": 11,
          "max_logit": 17.625,
          "min_logit": -12.125
        },
        {
          "step": 12,
          "max_logit": 17.125,
          "min_logit": -13.5625
        },
        {
          "step": 13,
          "max_logit": 13.3125,
          "min_logit": -16.125
        },
        {
          "step": 14,
          "max_logit": 19.125,
          "min_logit": -10.5
        },
        {
          "step": 15,
          "max_logit": 18.625,
          "min_logit": -14.3125
        },
        {
          "step": 16,
          "max_logit": 22.875,
          "min_logit": -8.0625
        }
      ],
      "raw_output": "There is no existence of a bed in the image, only a table is mentioned.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        4845,
        304,
        279,
        2168,
        11,
        1172,
        264,
        1965,
        374,
        9733,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a book in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 35,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 24.25,
          "min_logit": -9.75
        },
        {
          "step": 1,
          "max_logit": 28.125,
          "min_logit": -10.0625
        },
        {
          "step": 2,
          "max_logit": 24.5,
          "min_logit": -9.6875
        },
        {
          "step": 3,
          "max_logit": 21.5,
          "min_logit": -14.3125
        },
        {
          "step": 4,
          "max_logit": 24.25,
          "min_logit": -11.5625
        },
        {
          "step": 5,
          "max_logit": 24.0,
          "min_logit": -9.6875
        },
        {
          "step": 6,
          "max_logit": 18.875,
          "min_logit": -15.4375
        },
        {
          "step": 7,
          "max_logit": 24.125,
          "min_logit": -8.125
        },
        {
          "step": 8,
          "max_logit": 23.875,
          "min_logit": -10.0625
        },
        {
          "step": 9,
          "max_logit": 16.375,
          "min_logit": -15.8125
        },
        {
          "step": 10,
          "max_logit": 18.875,
          "min_logit": -11.6875
        },
        {
          "step": 11,
          "max_logit": 23.75,
          "min_logit": -6.9375
        }
      ],
      "raw_output": "There is no existence of a book in the image description.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        2311,
        304,
        279,
        2168,
        4008,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a person in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 36,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.75,
          "min_logit": -8.0
        },
        {
          "step": 1,
          "max_logit": 27.0,
          "min_logit": -4.40625
        },
        {
          "step": 2,
          "max_logit": 22.25,
          "min_logit": -9.4375
        },
        {
          "step": 3,
          "max_logit": 28.5,
          "min_logit": -8.3125
        },
        {
          "step": 4,
          "max_logit": 24.125,
          "min_logit": -9.125
        },
        {
          "step": 5,
          "max_logit": 17.125,
          "min_logit": -16.25
        },
        {
          "step": 6,
          "max_logit": 20.125,
          "min_logit": -12.0625
        },
        {
          "step": 7,
          "max_logit": 26.75,
          "min_logit": -8.5
        },
        {
          "step": 8,
          "max_logit": 19.375,
          "min_logit": -15.125
        },
        {
          "step": 9,
          "max_logit": 20.875,
          "min_logit": -10.0625
        }
      ],
      "raw_output": "Yes, there is a person in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        1697,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a car in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 37,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.0,
          "min_logit": -9.9375
        },
        {
          "step": 1,
          "max_logit": 28.625,
          "min_logit": -9.3125
        },
        {
          "step": 2,
          "max_logit": 25.25,
          "min_logit": -11.0625
        },
        {
          "step": 3,
          "max_logit": 20.125,
          "min_logit": -14.875
        },
        {
          "step": 4,
          "max_logit": 23.125,
          "min_logit": -12.3125
        },
        {
          "step": 5,
          "max_logit": 22.875,
          "min_logit": -11.375
        },
        {
          "step": 6,
          "max_logit": 19.375,
          "min_logit": -14.9375
        },
        {
          "step": 7,
          "max_logit": 23.875,
          "min_logit": -8.125
        },
        {
          "step": 8,
          "max_logit": 24.25,
          "min_logit": -11.375
        },
        {
          "step": 9,
          "max_logit": 16.625,
          "min_logit": -16.25
        },
        {
          "step": 10,
          "max_logit": 18.75,
          "min_logit": -11.9375
        }
      ],
      "raw_output": "There is no existence of a car in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        1803,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a spoon in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 38,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.0,
          "min_logit": -8.0
        },
        {
          "step": 1,
          "max_logit": 27.25,
          "min_logit": -4.46875
        },
        {
          "step": 2,
          "max_logit": 22.125,
          "min_logit": -10.6875
        },
        {
          "step": 3,
          "max_logit": 29.0,
          "min_logit": -9.25
        },
        {
          "step": 4,
          "max_logit": 25.125,
          "min_logit": -9.0625
        },
        {
          "step": 5,
          "max_logit": 18.375,
          "min_logit": -16.875
        },
        {
          "step": 6,
          "max_logit": 20.375,
          "min_logit": -12.75
        },
        {
          "step": 7,
          "max_logit": 26.75,
          "min_logit": -9.25
        },
        {
          "step": 8,
          "max_logit": 18.75,
          "min_logit": -15.0
        },
        {
          "step": 9,
          "max_logit": 23.125,
          "min_logit": -7.9375
        }
      ],
      "raw_output": "Yes, there is a spoon in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        45505,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a cup in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 39,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 24.5,
          "min_logit": -9.25
        },
        {
          "step": 1,
          "max_logit": 28.875,
          "min_logit": -9.625
        },
        {
          "step": 2,
          "max_logit": 25.125,
          "min_logit": -9.8125
        },
        {
          "step": 3,
          "max_logit": 20.0,
          "min_logit": -14.75
        },
        {
          "step": 4,
          "max_logit": 23.75,
          "min_logit": -11.1875
        },
        {
          "step": 5,
          "max_logit": 23.875,
          "min_logit": -10.4375
        },
        {
          "step": 6,
          "max_logit": 20.625,
          "min_logit": -15.625
        },
        {
          "step": 7,
          "max_logit": 24.375,
          "min_logit": -7.375
        },
        {
          "step": 8,
          "max_logit": 23.75,
          "min_logit": -11.3125
        },
        {
          "step": 9,
          "max_logit": 16.5,
          "min_logit": -16.25
        },
        {
          "step": 10,
          "max_logit": 18.625,
          "min_logit": -12.375
        },
        {
          "step": 11,
          "max_logit": 24.0,
          "min_logit": -6.71875
        }
      ],
      "raw_output": "There is no existence of a cup in the image description.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        10525,
        304,
        279,
        2168,
        4008,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a fork in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 40,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.125,
          "min_logit": -8.1875
        },
        {
          "step": 1,
          "max_logit": 27.5,
          "min_logit": -4.3125
        },
        {
          "step": 2,
          "max_logit": 22.75,
          "min_logit": -9.5625
        },
        {
          "step": 3,
          "max_logit": 29.25,
          "min_logit": -9.25
        },
        {
          "step": 4,
          "max_logit": 25.75,
          "min_logit": -8.0
        },
        {
          "step": 5,
          "max_logit": 20.25,
          "min_logit": -16.875
        },
        {
          "step": 6,
          "max_logit": 20.5,
          "min_logit": -12.375
        },
        {
          "step": 7,
          "max_logit": 27.125,
          "min_logit": -9.5625
        },
        {
          "step": 8,
          "max_logit": 19.0,
          "min_logit": -14.6875
        },
        {
          "step": 9,
          "max_logit": 23.25,
          "min_logit": -8.0
        }
      ],
      "raw_output": "Yes, there is a fork in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        22435,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a dining table in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 41,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 21.875,
          "min_logit": -9.0625
        },
        {
          "step": 1,
          "max_logit": 27.125,
          "min_logit": -4.3125
        },
        {
          "step": 2,
          "max_logit": 22.375,
          "min_logit": -10.25
        },
        {
          "step": 3,
          "max_logit": 28.75,
          "min_logit": -10.1875
        },
        {
          "step": 4,
          "max_logit": 25.25,
          "min_logit": -9.0625
        },
        {
          "step": 5,
          "max_logit": 17.875,
          "min_logit": -16.25
        },
        {
          "step": 6,
          "max_logit": 23.375,
          "min_logit": -14.875
        },
        {
          "step": 7,
          "max_logit": 22.75,
          "min_logit": -9.875
        },
        {
          "step": 8,
          "max_logit": 28.125,
          "min_logit": -9.4375
        },
        {
          "step": 9,
          "max_logit": 20.25,
          "min_logit": -14.125
        },
        {
          "step": 10,
          "max_logit": 24.5,
          "min_logit": -6.46875
        }
      ],
      "raw_output": "Yes, there is a dining table in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        17914,
        1965,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a tv in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 42,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.625,
          "min_logit": -8.125
        },
        {
          "step": 1,
          "max_logit": 23.125,
          "min_logit": -6.96875
        },
        {
          "step": 2,
          "max_logit": 24.375,
          "min_logit": -11.0625
        },
        {
          "step": 3,
          "max_logit": 30.0,
          "min_logit": -11.125
        },
        {
          "step": 4,
          "max_logit": 28.375,
          "min_logit": -10.5625
        },
        {
          "step": 5,
          "max_logit": 18.75,
          "min_logit": -15.1875
        },
        {
          "step": 6,
          "max_logit": 20.375,
          "min_logit": -13.5625
        },
        {
          "step": 7,
          "max_logit": 21.5,
          "min_logit": -10.25
        },
        {
          "step": 8,
          "max_logit": 27.25,
          "min_logit": -9.8125
        },
        {
          "step": 9,
          "max_logit": 23.0,
          "min_logit": -10.75
        },
        {
          "step": 10,
          "max_logit": 28.5,
          "min_logit": -8.25
        },
        {
          "step": 11,
          "max_logit": 20.875,
          "min_logit": -15.5
        },
        {
          "step": 12,
          "max_logit": 24.625,
          "min_logit": -7.75
        }
      ],
      "raw_output": "No, there is no television (TV) in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        2753,
        11,
        1052,
        374,
        902,
        12425,
        320,
        15653,
        8,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a person in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 43,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.625,
          "min_logit": -8.875
        },
        {
          "step": 1,
          "max_logit": 28.375,
          "min_logit": -9.0625
        },
        {
          "step": 2,
          "max_logit": 24.625,
          "min_logit": -11.4375
        },
        {
          "step": 3,
          "max_logit": 21.375,
          "min_logit": -16.0
        },
        {
          "step": 4,
          "max_logit": 24.75,
          "min_logit": -11.4375
        },
        {
          "step": 5,
          "max_logit": 23.75,
          "min_logit": -10.125
        },
        {
          "step": 6,
          "max_logit": 19.625,
          "min_logit": -15.5
        },
        {
          "step": 7,
          "max_logit": 23.0,
          "min_logit": -10.125
        },
        {
          "step": 8,
          "max_logit": 24.75,
          "min_logit": -8.6875
        },
        {
          "step": 9,
          "max_logit": 17.0,
          "min_logit": -15.5
        },
        {
          "step": 10,
          "max_logit": 19.75,
          "min_logit": -11.125
        }
      ],
      "raw_output": "There is no existence of a person in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        1697,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a toaster in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 44,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.875,
          "min_logit": -7.0625
        },
        {
          "step": 1,
          "max_logit": 27.875,
          "min_logit": -4.625
        },
        {
          "step": 2,
          "max_logit": 23.5,
          "min_logit": -9.4375
        },
        {
          "step": 3,
          "max_logit": 29.25,
          "min_logit": -8.1875
        },
        {
          "step": 4,
          "max_logit": 25.75,
          "min_logit": -8.0
        },
        {
          "step": 5,
          "max_logit": 17.375,
          "min_logit": -14.875
        },
        {
          "step": 6,
          "max_logit": 19.125,
          "min_logit": -13.0
        },
        {
          "step": 7,
          "max_logit": 26.125,
          "min_logit": -8.9375
        },
        {
          "step": 8,
          "max_logit": 18.0,
          "min_logit": -14.8125
        },
        {
          "step": 9,
          "max_logit": 22.375,
          "min_logit": -9.0
        }
      ],
      "raw_output": "Yes, there is a toaster in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        89818,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a book in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 45,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 26.0,
          "min_logit": -9.25
        },
        {
          "step": 1,
          "max_logit": 28.375,
          "min_logit": -9.875
        },
        {
          "step": 2,
          "max_logit": 25.0,
          "min_logit": -10.6875
        },
        {
          "step": 3,
          "max_logit": 22.75,
          "min_logit": -14.0
        },
        {
          "step": 4,
          "max_logit": 24.5,
          "min_logit": -12.125
        },
        {
          "step": 5,
          "max_logit": 24.0,
          "min_logit": -10.3125
        },
        {
          "step": 6,
          "max_logit": 19.75,
          "min_logit": -15.375
        },
        {
          "step": 7,
          "max_logit": 23.875,
          "min_logit": -8.6875
        },
        {
          "step": 8,
          "max_logit": 25.0,
          "min_logit": -9.3125
        },
        {
          "step": 9,
          "max_logit": 17.25,
          "min_logit": -15.125
        },
        {
          "step": 10,
          "max_logit": 19.75,
          "min_logit": -11.125
        },
        {
          "step": 11,
          "max_logit": 20.875,
          "min_logit": -11.5625
        }
      ],
      "raw_output": "There is no existence of a book in the image information.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        2311,
        304,
        279,
        2168,
        1995,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a microwave in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 46,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.875,
          "min_logit": -6.71875
        },
        {
          "step": 1,
          "max_logit": 27.625,
          "min_logit": -4.15625
        },
        {
          "step": 2,
          "max_logit": 23.25,
          "min_logit": -9.5625
        },
        {
          "step": 3,
          "max_logit": 28.375,
          "min_logit": -8.5625
        },
        {
          "step": 4,
          "max_logit": 25.125,
          "min_logit": -7.8125
        },
        {
          "step": 5,
          "max_logit": 18.375,
          "min_logit": -14.4375
        },
        {
          "step": 6,
          "max_logit": 19.0,
          "min_logit": -13.5
        },
        {
          "step": 7,
          "max_logit": 26.5,
          "min_logit": -8.875
        },
        {
          "step": 8,
          "max_logit": 18.5,
          "min_logit": -15.375
        },
        {
          "step": 9,
          "max_logit": 22.375,
          "min_logit": -8.75
        }
      ],
      "raw_output": "Yes, there is a microwave in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        41274,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a bottle in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 47,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 26.5,
          "min_logit": -9.125
        },
        {
          "step": 1,
          "max_logit": 29.125,
          "min_logit": -9.6875
        },
        {
          "step": 2,
          "max_logit": 25.875,
          "min_logit": -10.1875
        },
        {
          "step": 3,
          "max_logit": 22.5,
          "min_logit": -14.375
        },
        {
          "step": 4,
          "max_logit": 24.375,
          "min_logit": -11.9375
        },
        {
          "step": 5,
          "max_logit": 22.5,
          "min_logit": -11.9375
        },
        {
          "step": 6,
          "max_logit": 20.25,
          "min_logit": -15.25
        },
        {
          "step": 7,
          "max_logit": 24.5,
          "min_logit": -7.78125
        },
        {
          "step": 8,
          "max_logit": 25.0,
          "min_logit": -9.625
        },
        {
          "step": 9,
          "max_logit": 17.375,
          "min_logit": -15.375
        },
        {
          "step": 10,
          "max_logit": 19.625,
          "min_logit": -11.25
        },
        {
          "step": 11,
          "max_logit": 21.875,
          "min_logit": -11.0
        }
      ],
      "raw_output": "There is no existence of a bottle in the image information.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        16486,
        304,
        279,
        2168,
        1995,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a backpack in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 48,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.0,
          "min_logit": -8.875
        },
        {
          "step": 1,
          "max_logit": 26.75,
          "min_logit": -4.65625
        },
        {
          "step": 2,
          "max_logit": 21.625,
          "min_logit": -12.75
        },
        {
          "step": 3,
          "max_logit": 28.5,
          "min_logit": -8.6875
        },
        {
          "step": 4,
          "max_logit": 24.875,
          "min_logit": -8.5625
        },
        {
          "step": 5,
          "max_logit": 16.875,
          "min_logit": -17.5
        },
        {
          "step": 6,
          "max_logit": 20.25,
          "min_logit": -11.875
        },
        {
          "step": 7,
          "max_logit": 25.75,
          "min_logit": -10.0
        },
        {
          "step": 8,
          "max_logit": 18.125,
          "min_logit": -16.25
        },
        {
          "step": 9,
          "max_logit": 23.875,
          "min_logit": -6.78125
        }
      ],
      "raw_output": "Yes, there is a backpack in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        33136,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a handbag in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 49,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 22.625,
          "min_logit": -9.6875
        },
        {
          "step": 1,
          "max_logit": 27.0,
          "min_logit": -4.75
        },
        {
          "step": 2,
          "max_logit": 22.625,
          "min_logit": -11.1875
        },
        {
          "step": 3,
          "max_logit": 28.625,
          "min_logit": -8.25
        },
        {
          "step": 4,
          "max_logit": 25.25,
          "min_logit": -8.6875
        },
        {
          "step": 5,
          "max_logit": 18.875,
          "min_logit": -19.125
        },
        {
          "step": 6,
          "max_logit": 23.0,
          "min_logit": -14.375
        },
        {
          "step": 7,
          "max_logit": 20.875,
          "min_logit": -11.9375
        },
        {
          "step": 8,
          "max_logit": 26.75,
          "min_logit": -9.75
        },
        {
          "step": 9,
          "max_logit": 18.75,
          "min_logit": -15.9375
        },
        {
          "step": 10,
          "max_logit": 24.125,
          "min_logit": -7.15625
        }
      ],
      "raw_output": "Yes, there is a handbag in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        1424,
        21250,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a person in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 50,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 22.5,
          "min_logit": -9.625
        },
        {
          "step": 1,
          "max_logit": 26.0,
          "min_logit": -9.4375
        },
        {
          "step": 2,
          "max_logit": 20.5,
          "min_logit": -10.125
        },
        {
          "step": 3,
          "max_logit": 14.25,
          "min_logit": -17.0
        },
        {
          "step": 4,
          "max_logit": 16.625,
          "min_logit": -13.375
        },
        {
          "step": 5,
          "max_logit": 22.5,
          "min_logit": -11.4375
        },
        {
          "step": 6,
          "max_logit": 17.5,
          "min_logit": -16.75
        },
        {
          "step": 7,
          "max_logit": 19.0,
          "min_logit": -11.6875
        }
      ],
      "raw_output": "There is a person in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        264,
        1697,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a car in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 51,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.25,
          "min_logit": -10.0
        },
        {
          "step": 1,
          "max_logit": 28.875,
          "min_logit": -9.5625
        },
        {
          "step": 2,
          "max_logit": 25.75,
          "min_logit": -11.3125
        },
        {
          "step": 3,
          "max_logit": 21.375,
          "min_logit": -15.3125
        },
        {
          "step": 4,
          "max_logit": 23.5,
          "min_logit": -12.4375
        },
        {
          "step": 5,
          "max_logit": 23.125,
          "min_logit": -11.125
        },
        {
          "step": 6,
          "max_logit": 19.25,
          "min_logit": -15.4375
        },
        {
          "step": 7,
          "max_logit": 23.75,
          "min_logit": -8.375
        },
        {
          "step": 8,
          "max_logit": 23.125,
          "min_logit": -11.0
        },
        {
          "step": 9,
          "max_logit": 16.25,
          "min_logit": -17.25
        },
        {
          "step": 10,
          "max_logit": 19.375,
          "min_logit": -11.3125
        }
      ],
      "raw_output": "There is no existence of a car in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        1803,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a skis in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 52,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 22.75,
          "min_logit": -8.375
        },
        {
          "step": 1,
          "max_logit": 27.375,
          "min_logit": -4.71875
        },
        {
          "step": 2,
          "max_logit": 20.5,
          "min_logit": -12.0
        },
        {
          "step": 3,
          "max_logit": 27.75,
          "min_logit": -8.125
        },
        {
          "step": 4,
          "max_logit": 17.25,
          "min_logit": -15.875
        },
        {
          "step": 5,
          "max_logit": 26.0,
          "min_logit": -13.125
        },
        {
          "step": 6,
          "max_logit": 20.5,
          "min_logit": -12.625
        },
        {
          "step": 7,
          "max_logit": 27.0,
          "min_logit": -9.375
        },
        {
          "step": 8,
          "max_logit": 19.625,
          "min_logit": -16.625
        },
        {
          "step": 9,
          "max_logit": 23.125,
          "min_logit": -7.125
        }
      ],
      "raw_output": "Yes, there are skis in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        525,
        1901,
        285,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a snowboard in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 53,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 24.375,
          "min_logit": -9.1875
        },
        {
          "step": 1,
          "max_logit": 28.5,
          "min_logit": -9.6875
        },
        {
          "step": 2,
          "max_logit": 25.75,
          "min_logit": -11.4375
        },
        {
          "step": 3,
          "max_logit": 20.875,
          "min_logit": -15.875
        },
        {
          "step": 4,
          "max_logit": 23.875,
          "min_logit": -12.125
        },
        {
          "step": 5,
          "max_logit": 23.125,
          "min_logit": -13.0625
        },
        {
          "step": 6,
          "max_logit": 20.625,
          "min_logit": -17.875
        },
        {
          "step": 7,
          "max_logit": 25.25,
          "min_logit": -13.0
        },
        {
          "step": 8,
          "max_logit": 24.125,
          "min_logit": -7.1875
        },
        {
          "step": 9,
          "max_logit": 24.0,
          "min_logit": -10.1875
        },
        {
          "step": 10,
          "max_logit": 16.625,
          "min_logit": -17.25
        },
        {
          "step": 11,
          "max_logit": 19.5,
          "min_logit": -11.375
        },
        {
          "step": 12,
          "max_logit": 17.375,
          "min_logit": -12.9375
        },
        {
          "step": 13,
          "max_logit": 15.75,
          "min_logit": -14.6875
        },
        {
          "step": 14,
          "max_logit": 19.625,
          "min_logit": -12.0
        },
        {
          "step": 15,
          "max_logit": 21.5,
          "min_logit": -13.0625
        },
        {
          "step": 16,
          "max_logit": 13.75,
          "min_logit": -18.25
        },
        {
          "step": 17,
          "max_logit": 22.125,
          "min_logit": -8.375
        }
      ],
      "raw_output": "There is no existence of a snowboard in the image, so it cannot be identified.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        11794,
        2482,
        304,
        279,
        2168,
        11,
        773,
        432,
        4157,
        387,
        10820,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a bird in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 54,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.875,
          "min_logit": -8.1875
        },
        {
          "step": 1,
          "max_logit": 27.125,
          "min_logit": -4.71875
        },
        {
          "step": 2,
          "max_logit": 22.125,
          "min_logit": -11.4375
        },
        {
          "step": 3,
          "max_logit": 29.25,
          "min_logit": -8.8125
        },
        {
          "step": 4,
          "max_logit": 25.5,
          "min_logit": -9.1875
        },
        {
          "step": 5,
          "max_logit": 15.875,
          "min_logit": -17.375
        },
        {
          "step": 6,
          "max_logit": 18.5,
          "min_logit": -13.5
        },
        {
          "step": 7,
          "max_logit": 26.25,
          "min_logit": -11.1875
        },
        {
          "step": 8,
          "max_logit": 16.875,
          "min_logit": -17.0
        },
        {
          "step": 9,
          "max_logit": 20.875,
          "min_logit": -9.5
        }
      ],
      "raw_output": "Yes, there is a bird in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        11958,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a handbag in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 55,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.625,
          "min_logit": -10.125
        },
        {
          "step": 1,
          "max_logit": 29.875,
          "min_logit": -9.75
        },
        {
          "step": 2,
          "max_logit": 26.5,
          "min_logit": -11.4375
        },
        {
          "step": 3,
          "max_logit": 21.5,
          "min_logit": -15.0
        },
        {
          "step": 4,
          "max_logit": 24.875,
          "min_logit": -10.625
        },
        {
          "step": 5,
          "max_logit": 22.5,
          "min_logit": -11.375
        },
        {
          "step": 6,
          "max_logit": 20.375,
          "min_logit": -15.8125
        },
        {
          "step": 7,
          "max_logit": 27.5,
          "min_logit": -14.375
        },
        {
          "step": 8,
          "max_logit": 24.75,
          "min_logit": -7.125
        },
        {
          "step": 9,
          "max_logit": 24.375,
          "min_logit": -10.1875
        },
        {
          "step": 10,
          "max_logit": 16.375,
          "min_logit": -15.875
        },
        {
          "step": 11,
          "max_logit": 19.375,
          "min_logit": -11.25
        }
      ],
      "raw_output": "There is no existence of a handbag in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        1424,
        21250,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a person in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 56,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 22.375,
          "min_logit": -9.6875
        },
        {
          "step": 1,
          "max_logit": 26.125,
          "min_logit": -8.6875
        },
        {
          "step": 2,
          "max_logit": 21.0,
          "min_logit": -11.5
        },
        {
          "step": 3,
          "max_logit": 17.125,
          "min_logit": -15.0625
        },
        {
          "step": 4,
          "max_logit": 24.0,
          "min_logit": -10.75
        },
        {
          "step": 5,
          "max_logit": 20.625,
          "min_logit": -11.125
        },
        {
          "step": 6,
          "max_logit": 16.125,
          "min_logit": -14.0
        },
        {
          "step": 7,
          "max_logit": 21.5,
          "min_logit": -11.0
        },
        {
          "step": 8,
          "max_logit": 23.0,
          "min_logit": -9.9375
        },
        {
          "step": 9,
          "max_logit": 14.9375,
          "min_logit": -16.75
        },
        {
          "step": 10,
          "max_logit": 19.5,
          "min_logit": -11.0625
        }
      ],
      "raw_output": "There is no existence of any person in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        894,
        1697,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a car in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 57,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.0,
          "min_logit": -9.75
        },
        {
          "step": 1,
          "max_logit": 28.625,
          "min_logit": -9.75
        },
        {
          "step": 2,
          "max_logit": 25.25,
          "min_logit": -11.375
        },
        {
          "step": 3,
          "max_logit": 20.0,
          "min_logit": -14.875
        },
        {
          "step": 4,
          "max_logit": 23.875,
          "min_logit": -11.75
        },
        {
          "step": 5,
          "max_logit": 22.5,
          "min_logit": -11.0625
        },
        {
          "step": 6,
          "max_logit": 19.0,
          "min_logit": -15.25
        },
        {
          "step": 7,
          "max_logit": 23.625,
          "min_logit": -8.8125
        },
        {
          "step": 8,
          "max_logit": 23.625,
          "min_logit": -10.5625
        },
        {
          "step": 9,
          "max_logit": 15.9375,
          "min_logit": -16.0
        },
        {
          "step": 10,
          "max_logit": 19.75,
          "min_logit": -10.875
        }
      ],
      "raw_output": "There is no existence of a car in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        1803,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a boat in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 58,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.75,
          "min_logit": -8.4375
        },
        {
          "step": 1,
          "max_logit": 26.625,
          "min_logit": -4.75
        },
        {
          "step": 2,
          "max_logit": 20.5,
          "min_logit": -13.875
        },
        {
          "step": 3,
          "max_logit": 28.125,
          "min_logit": -9.8125
        },
        {
          "step": 4,
          "max_logit": 17.25,
          "min_logit": -15.6875
        },
        {
          "step": 5,
          "max_logit": 19.75,
          "min_logit": -13.625
        },
        {
          "step": 6,
          "max_logit": 24.125,
          "min_logit": -11.8125
        },
        {
          "step": 7,
          "max_logit": 17.0,
          "min_logit": -17.75
        },
        {
          "step": 8,
          "max_logit": 22.125,
          "min_logit": -9.5625
        }
      ],
      "raw_output": "Yes, there are boats in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        525,
        31631,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a chair in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 59,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.875,
          "min_logit": -9.5
        },
        {
          "step": 1,
          "max_logit": 28.375,
          "min_logit": -9.6875
        },
        {
          "step": 2,
          "max_logit": 24.5,
          "min_logit": -10.75
        },
        {
          "step": 3,
          "max_logit": 21.0,
          "min_logit": -13.6875
        },
        {
          "step": 4,
          "max_logit": 24.375,
          "min_logit": -10.5625
        },
        {
          "step": 5,
          "max_logit": 20.875,
          "min_logit": -10.625
        },
        {
          "step": 6,
          "max_logit": 18.5,
          "min_logit": -15.9375
        },
        {
          "step": 7,
          "max_logit": 24.625,
          "min_logit": -7.21875
        },
        {
          "step": 8,
          "max_logit": 24.375,
          "min_logit": -10.0625
        },
        {
          "step": 9,
          "max_logit": 16.125,
          "min_logit": -16.125
        },
        {
          "step": 10,
          "max_logit": 19.25,
          "min_logit": -11.4375
        }
      ],
      "raw_output": "There is no existence of a chair in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        10496,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a person in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 60,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 22.375,
          "min_logit": -10.0625
        },
        {
          "step": 1,
          "max_logit": 25.5,
          "min_logit": -4.71875
        },
        {
          "step": 2,
          "max_logit": 20.875,
          "min_logit": -11.375
        },
        {
          "step": 3,
          "max_logit": 27.25,
          "min_logit": -8.4375
        },
        {
          "step": 4,
          "max_logit": 18.0,
          "min_logit": -13.5
        },
        {
          "step": 5,
          "max_logit": 19.75,
          "min_logit": -13.5
        },
        {
          "step": 6,
          "max_logit": 25.375,
          "min_logit": -10.6875
        },
        {
          "step": 7,
          "max_logit": 18.75,
          "min_logit": -16.25
        },
        {
          "step": 8,
          "max_logit": 20.875,
          "min_logit": -9.5
        }
      ],
      "raw_output": "Yes, there are people in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        525,
        1251,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a car in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 61,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.5,
          "min_logit": -10.375
        },
        {
          "step": 1,
          "max_logit": 28.5,
          "min_logit": -9.8125
        },
        {
          "step": 2,
          "max_logit": 25.375,
          "min_logit": -11.4375
        },
        {
          "step": 3,
          "max_logit": 20.75,
          "min_logit": -15.125
        },
        {
          "step": 4,
          "max_logit": 23.125,
          "min_logit": -12.8125
        },
        {
          "step": 5,
          "max_logit": 22.125,
          "min_logit": -11.0625
        },
        {
          "step": 6,
          "max_logit": 19.0,
          "min_logit": -15.375
        },
        {
          "step": 7,
          "max_logit": 23.5,
          "min_logit": -9.0
        },
        {
          "step": 8,
          "max_logit": 24.125,
          "min_logit": -10.8125
        },
        {
          "step": 9,
          "max_logit": 16.5,
          "min_logit": -16.0
        },
        {
          "step": 10,
          "max_logit": 19.25,
          "min_logit": -11.375
        }
      ],
      "raw_output": "There is no existence of a car in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        1803,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there an orange in the imange?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 62,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 20.875,
          "min_logit": -11.125
        },
        {
          "step": 1,
          "max_logit": 17.25,
          "min_logit": -11.4375
        },
        {
          "step": 2,
          "max_logit": 27.75,
          "min_logit": -15.9375
        },
        {
          "step": 3,
          "max_logit": 22.375,
          "min_logit": -13.625
        },
        {
          "step": 4,
          "max_logit": 28.125,
          "min_logit": -12.0
        },
        {
          "step": 5,
          "max_logit": 32.75,
          "min_logit": -7.15625
        },
        {
          "step": 6,
          "max_logit": 23.75,
          "min_logit": -4.0625
        },
        {
          "step": 7,
          "max_logit": 22.0,
          "min_logit": -4.46875
        },
        {
          "step": 8,
          "max_logit": 24.75,
          "min_logit": -3.1875
        },
        {
          "step": 9,
          "max_logit": 35.75,
          "min_logit": -9.25
        },
        {
          "step": 10,
          "max_logit": 24.25,
          "min_logit": -3.84375
        },
        {
          "step": 11,
          "max_logit": 24.75,
          "min_logit": -3.953125
        },
        {
          "step": 12,
          "max_logit": 25.125,
          "min_logit": -7.09375
        },
        {
          "step": 13,
          "max_logit": 30.875,
          "min_logit": -10.4375
        },
        {
          "step": 14,
          "max_logit": 27.75,
          "min_logit": -5.75
        },
        {
          "step": 15,
          "max_logit": 24.125,
          "min_logit": -5.125
        },
        {
          "step": 16,
          "max_logit": 24.5,
          "min_logit": -4.8125
        },
        {
          "step": 17,
          "max_logit": 38.75,
          "min_logit": -10.8125
        },
        {
          "step": 18,
          "max_logit": 26.75,
          "min_logit": -4.75
        },
        {
          "step": 19,
          "max_logit": 24.0,
          "min_logit": -3.734375
        },
        {
          "step": 20,
          "max_logit": 25.25,
          "min_logit": -4.21875
        },
        {
          "step": 21,
          "max_logit": 32.25,
          "min_logit": -14.8125
        },
        {
          "step": 22,
          "max_logit": 32.5,
          "min_logit": -19.375
        }
      ],
      "raw_output": " an orange(697,703),(745,784)",
      "enforced_output": "No",
      "generated_tokens": [
        151646,
        458,
        18575,
        151647,
        151648,
        7,
        21,
        24,
        22,
        11,
        22,
        15,
        18,
        23547,
        22,
        19,
        20,
        11,
        22,
        23,
        19,
        8,
        151649,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a dining table in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 63,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 24.25,
          "min_logit": -10.25
        },
        {
          "step": 1,
          "max_logit": 27.875,
          "min_logit": -9.75
        },
        {
          "step": 2,
          "max_logit": 24.5,
          "min_logit": -10.375
        },
        {
          "step": 3,
          "max_logit": 20.375,
          "min_logit": -14.5
        },
        {
          "step": 4,
          "max_logit": 23.375,
          "min_logit": -12.0
        },
        {
          "step": 5,
          "max_logit": 22.25,
          "min_logit": -8.8125
        },
        {
          "step": 6,
          "max_logit": 20.0,
          "min_logit": -14.375
        },
        {
          "step": 7,
          "max_logit": 25.25,
          "min_logit": -14.5
        },
        {
          "step": 8,
          "max_logit": 25.125,
          "min_logit": -7.15625
        },
        {
          "step": 9,
          "max_logit": 24.375,
          "min_logit": -10.375
        },
        {
          "step": 10,
          "max_logit": 16.375,
          "min_logit": -16.0
        },
        {
          "step": 11,
          "max_logit": 18.875,
          "min_logit": -11.5625
        },
        {
          "step": 12,
          "max_logit": 24.0,
          "min_logit": -6.5
        }
      ],
      "raw_output": "There is no existence of a dining table in the image description.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        17914,
        1965,
        304,
        279,
        2168,
        4008,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a bottle in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 64,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.625,
          "min_logit": -9.125
        },
        {
          "step": 1,
          "max_logit": 27.625,
          "min_logit": -9.5625
        },
        {
          "step": 2,
          "max_logit": 23.5,
          "min_logit": -11.0625
        },
        {
          "step": 3,
          "max_logit": 20.5,
          "min_logit": -14.125
        },
        {
          "step": 4,
          "max_logit": 23.625,
          "min_logit": -11.5
        },
        {
          "step": 5,
          "max_logit": 22.375,
          "min_logit": -11.25
        },
        {
          "step": 6,
          "max_logit": 19.5,
          "min_logit": -17.0
        },
        {
          "step": 7,
          "max_logit": 23.5,
          "min_logit": -7.78125
        },
        {
          "step": 8,
          "max_logit": 23.375,
          "min_logit": -10.875
        },
        {
          "step": 9,
          "max_logit": 16.125,
          "min_logit": -16.125
        },
        {
          "step": 10,
          "max_logit": 19.25,
          "min_logit": -11.5625
        }
      ],
      "raw_output": "There is no existence of a bottle in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        16486,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a cup in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 65,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 24.5,
          "min_logit": -9.3125
        },
        {
          "step": 1,
          "max_logit": 28.375,
          "min_logit": -9.5625
        },
        {
          "step": 2,
          "max_logit": 24.875,
          "min_logit": -10.6875
        },
        {
          "step": 3,
          "max_logit": 21.375,
          "min_logit": -14.625
        },
        {
          "step": 4,
          "max_logit": 23.75,
          "min_logit": -11.4375
        },
        {
          "step": 5,
          "max_logit": 22.5,
          "min_logit": -10.9375
        },
        {
          "step": 6,
          "max_logit": 20.125,
          "min_logit": -16.125
        },
        {
          "step": 7,
          "max_logit": 24.125,
          "min_logit": -8.0625
        },
        {
          "step": 8,
          "max_logit": 24.375,
          "min_logit": -10.3125
        },
        {
          "step": 9,
          "max_logit": 16.75,
          "min_logit": -15.875
        },
        {
          "step": 10,
          "max_logit": 19.25,
          "min_logit": -11.5625
        },
        {
          "step": 11,
          "max_logit": 22.0,
          "min_logit": -10.0625
        }
      ],
      "raw_output": "There is no existence of a cup in the image information.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        10525,
        304,
        279,
        2168,
        1995,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a backpack in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 66,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.125,
          "min_logit": -9.8125
        },
        {
          "step": 1,
          "max_logit": 28.0,
          "min_logit": -10.3125
        },
        {
          "step": 2,
          "max_logit": 23.75,
          "min_logit": -11.5
        },
        {
          "step": 3,
          "max_logit": 17.0,
          "min_logit": -15.6875
        },
        {
          "step": 4,
          "max_logit": 22.75,
          "min_logit": -11.625
        },
        {
          "step": 5,
          "max_logit": 27.125,
          "min_logit": -9.75
        },
        {
          "step": 6,
          "max_logit": 18.75,
          "min_logit": -17.375
        },
        {
          "step": 7,
          "max_logit": 23.875,
          "min_logit": -7.5
        }
      ],
      "raw_output": "There is no backpack in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        33136,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a handbag in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 67,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.875,
          "min_logit": -9.9375
        },
        {
          "step": 1,
          "max_logit": 28.625,
          "min_logit": -9.75
        },
        {
          "step": 2,
          "max_logit": 24.625,
          "min_logit": -10.6875
        },
        {
          "step": 3,
          "max_logit": 19.5,
          "min_logit": -14.375
        },
        {
          "step": 4,
          "max_logit": 29.875,
          "min_logit": -14.75
        },
        {
          "step": 5,
          "max_logit": 22.125,
          "min_logit": -11.625
        },
        {
          "step": 6,
          "max_logit": 27.75,
          "min_logit": -9.8125
        },
        {
          "step": 7,
          "max_logit": 19.75,
          "min_logit": -17.375
        },
        {
          "step": 8,
          "max_logit": 24.0,
          "min_logit": -7.9375
        }
      ],
      "raw_output": "There is no handbag in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        1424,
        21250,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a person in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 68,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.375,
          "min_logit": -9.875
        },
        {
          "step": 1,
          "max_logit": 27.125,
          "min_logit": -9.4375
        },
        {
          "step": 2,
          "max_logit": 20.5,
          "min_logit": -11.0
        },
        {
          "step": 3,
          "max_logit": 13.375,
          "min_logit": -17.125
        },
        {
          "step": 4,
          "max_logit": 18.75,
          "min_logit": -13.5
        },
        {
          "step": 5,
          "max_logit": 24.5,
          "min_logit": -9.4375
        },
        {
          "step": 6,
          "max_logit": 17.5,
          "min_logit": -16.875
        },
        {
          "step": 7,
          "max_logit": 21.875,
          "min_logit": -8.6875
        }
      ],
      "raw_output": "There is a person in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        264,
        1697,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a car in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 69,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 24.625,
          "min_logit": -8.4375
        },
        {
          "step": 1,
          "max_logit": 28.125,
          "min_logit": -9.6875
        },
        {
          "step": 2,
          "max_logit": 24.5,
          "min_logit": -11.1875
        },
        {
          "step": 3,
          "max_logit": 18.125,
          "min_logit": -15.0625
        },
        {
          "step": 4,
          "max_logit": 23.25,
          "min_logit": -11.0
        },
        {
          "step": 5,
          "max_logit": 28.125,
          "min_logit": -9.125
        },
        {
          "step": 6,
          "max_logit": 19.5,
          "min_logit": -17.75
        },
        {
          "step": 7,
          "max_logit": 24.75,
          "min_logit": -7.3125
        }
      ],
      "raw_output": "There is no car in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        1803,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a bus in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 70,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 24.0,
          "min_logit": -8.0
        },
        {
          "step": 1,
          "max_logit": 27.0,
          "min_logit": -4.75
        },
        {
          "step": 2,
          "max_logit": 23.0,
          "min_logit": -9.9375
        },
        {
          "step": 3,
          "max_logit": 29.5,
          "min_logit": -8.9375
        },
        {
          "step": 4,
          "max_logit": 25.625,
          "min_logit": -8.625
        },
        {
          "step": 5,
          "max_logit": 13.9375,
          "min_logit": -18.25
        },
        {
          "step": 6,
          "max_logit": 21.5,
          "min_logit": -11.5625
        },
        {
          "step": 7,
          "max_logit": 27.375,
          "min_logit": -8.5
        },
        {
          "step": 8,
          "max_logit": 19.0,
          "min_logit": -15.875
        },
        {
          "step": 9,
          "max_logit": 24.5,
          "min_logit": -7.34375
        }
      ],
      "raw_output": "Yes, there is a bus in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        5828,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a traffic light in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 71,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.0,
          "min_logit": -9.375
        },
        {
          "step": 1,
          "max_logit": 28.875,
          "min_logit": -10.375
        },
        {
          "step": 2,
          "max_logit": 24.5,
          "min_logit": -12.5
        },
        {
          "step": 3,
          "max_logit": 19.0,
          "min_logit": -15.3125
        },
        {
          "step": 4,
          "max_logit": 22.875,
          "min_logit": -17.125
        },
        {
          "step": 5,
          "max_logit": 24.25,
          "min_logit": -11.125
        },
        {
          "step": 6,
          "max_logit": 28.375,
          "min_logit": -9.1875
        },
        {
          "step": 7,
          "max_logit": 19.75,
          "min_logit": -17.625
        },
        {
          "step": 8,
          "max_logit": 24.5,
          "min_logit": -7.65625
        }
      ],
      "raw_output": "There is no traffic light in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        9442,
        3100,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a person in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 72,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 24.75,
          "min_logit": -7.34375
        },
        {
          "step": 1,
          "max_logit": 27.625,
          "min_logit": -4.40625
        },
        {
          "step": 2,
          "max_logit": 22.875,
          "min_logit": -9.0
        },
        {
          "step": 3,
          "max_logit": 29.0,
          "min_logit": -8.5625
        },
        {
          "step": 4,
          "max_logit": 25.375,
          "min_logit": -8.3125
        },
        {
          "step": 5,
          "max_logit": 17.25,
          "min_logit": -15.75
        },
        {
          "step": 6,
          "max_logit": 20.25,
          "min_logit": -12.25
        },
        {
          "step": 7,
          "max_logit": 27.625,
          "min_logit": -6.90625
        },
        {
          "step": 8,
          "max_logit": 20.375,
          "min_logit": -14.5625
        },
        {
          "step": 9,
          "max_logit": 19.625,
          "min_logit": -12.0625
        }
      ],
      "raw_output": "Yes, there is a person in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        1697,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a car in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 73,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.5,
          "min_logit": -9.9375
        },
        {
          "step": 1,
          "max_logit": 28.625,
          "min_logit": -9.6875
        },
        {
          "step": 2,
          "max_logit": 25.75,
          "min_logit": -10.25
        },
        {
          "step": 3,
          "max_logit": 19.625,
          "min_logit": -14.5625
        },
        {
          "step": 4,
          "max_logit": 23.25,
          "min_logit": -12.3125
        },
        {
          "step": 5,
          "max_logit": 23.125,
          "min_logit": -10.875
        },
        {
          "step": 6,
          "max_logit": 19.5,
          "min_logit": -14.9375
        },
        {
          "step": 7,
          "max_logit": 23.875,
          "min_logit": -8.625
        },
        {
          "step": 8,
          "max_logit": 24.75,
          "min_logit": -10.75
        },
        {
          "step": 9,
          "max_logit": 16.75,
          "min_logit": -16.125
        },
        {
          "step": 10,
          "max_logit": 19.125,
          "min_logit": -11.75
        },
        {
          "step": 11,
          "max_logit": 21.875,
          "min_logit": -10.25
        }
      ],
      "raw_output": "There is no existence of a car in the image information.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        1803,
        304,
        279,
        2168,
        1995,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a dining table in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 74,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 22.75,
          "min_logit": -8.625
        },
        {
          "step": 1,
          "max_logit": 27.5,
          "min_logit": -4.40625
        },
        {
          "step": 2,
          "max_logit": 22.625,
          "min_logit": -8.875
        },
        {
          "step": 3,
          "max_logit": 28.875,
          "min_logit": -10.25
        },
        {
          "step": 4,
          "max_logit": 25.375,
          "min_logit": -8.875
        },
        {
          "step": 5,
          "max_logit": 18.75,
          "min_logit": -14.875
        },
        {
          "step": 6,
          "max_logit": 24.0,
          "min_logit": -14.1875
        },
        {
          "step": 7,
          "max_logit": 22.5,
          "min_logit": -10.25
        },
        {
          "step": 8,
          "max_logit": 27.75,
          "min_logit": -8.875
        },
        {
          "step": 9,
          "max_logit": 20.0,
          "min_logit": -13.625
        },
        {
          "step": 10,
          "max_logit": 24.25,
          "min_logit": -7.53125
        }
      ],
      "raw_output": "Yes, there is a dining table in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        17914,
        1965,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a cup in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 75,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 24.75,
          "min_logit": -9.375
        },
        {
          "step": 1,
          "max_logit": 28.625,
          "min_logit": -9.5625
        },
        {
          "step": 2,
          "max_logit": 25.25,
          "min_logit": -10.375
        },
        {
          "step": 3,
          "max_logit": 20.5,
          "min_logit": -15.0
        },
        {
          "step": 4,
          "max_logit": 24.0,
          "min_logit": -11.0625
        },
        {
          "step": 5,
          "max_logit": 22.625,
          "min_logit": -11.625
        },
        {
          "step": 6,
          "max_logit": 20.875,
          "min_logit": -15.6875
        },
        {
          "step": 7,
          "max_logit": 24.625,
          "min_logit": -6.8125
        },
        {
          "step": 8,
          "max_logit": 24.375,
          "min_logit": -10.5
        },
        {
          "step": 9,
          "max_logit": 16.875,
          "min_logit": -16.125
        },
        {
          "step": 10,
          "max_logit": 19.0,
          "min_logit": -12.0625
        }
      ],
      "raw_output": "There is no existence of a cup in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        10525,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a chair in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 76,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.5,
          "min_logit": -8.5625
        },
        {
          "step": 1,
          "max_logit": 27.75,
          "min_logit": -4.3125
        },
        {
          "step": 2,
          "max_logit": 22.625,
          "min_logit": -8.8125
        },
        {
          "step": 3,
          "max_logit": 28.875,
          "min_logit": -9.5625
        },
        {
          "step": 4,
          "max_logit": 24.125,
          "min_logit": -9.5
        },
        {
          "step": 5,
          "max_logit": 17.625,
          "min_logit": -16.0
        },
        {
          "step": 6,
          "max_logit": 21.875,
          "min_logit": -9.5625
        },
        {
          "step": 7,
          "max_logit": 27.25,
          "min_logit": -9.1875
        },
        {
          "step": 8,
          "max_logit": 19.625,
          "min_logit": -14.3125
        },
        {
          "step": 9,
          "max_logit": 23.5,
          "min_logit": -7.21875
        }
      ],
      "raw_output": "Yes, there is a chair in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        10496,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a couch in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 77,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.375,
          "min_logit": -9.375
        },
        {
          "step": 1,
          "max_logit": 28.875,
          "min_logit": -9.8125
        },
        {
          "step": 2,
          "max_logit": 26.0,
          "min_logit": -10.25
        },
        {
          "step": 3,
          "max_logit": 18.875,
          "min_logit": -14.0
        },
        {
          "step": 4,
          "max_logit": 23.625,
          "min_logit": -12.0625
        },
        {
          "step": 5,
          "max_logit": 23.625,
          "min_logit": -9.0625
        },
        {
          "step": 6,
          "max_logit": 20.25,
          "min_logit": -14.0
        },
        {
          "step": 7,
          "max_logit": 24.875,
          "min_logit": -6.46875
        },
        {
          "step": 8,
          "max_logit": 24.5,
          "min_logit": -10.3125
        },
        {
          "step": 9,
          "max_logit": 16.375,
          "min_logit": -16.5
        },
        {
          "step": 10,
          "max_logit": 18.875,
          "min_logit": -11.8125
        },
        {
          "step": 11,
          "max_logit": 21.625,
          "min_logit": -10.625
        }
      ],
      "raw_output": "There is no existence of a couch in the image information.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        26148,
        304,
        279,
        2168,
        1995,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a person in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 78,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.5,
          "min_logit": -8.875
        },
        {
          "step": 1,
          "max_logit": 26.5,
          "min_logit": -9.0
        },
        {
          "step": 2,
          "max_logit": 21.625,
          "min_logit": -9.875
        },
        {
          "step": 3,
          "max_logit": 14.25,
          "min_logit": -15.9375
        },
        {
          "step": 4,
          "max_logit": 20.125,
          "min_logit": -11.625
        },
        {
          "step": 5,
          "max_logit": 25.875,
          "min_logit": -8.375
        },
        {
          "step": 6,
          "max_logit": 18.25,
          "min_logit": -15.6875
        },
        {
          "step": 7,
          "max_logit": 21.375,
          "min_logit": -8.4375
        }
      ],
      "raw_output": "There is a person in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        3862,
        374,
        264,
        1697,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a car in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 79,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 26.125,
          "min_logit": -9.25
        },
        {
          "step": 1,
          "max_logit": 28.5,
          "min_logit": -9.375
        },
        {
          "step": 2,
          "max_logit": 25.625,
          "min_logit": -11.375
        },
        {
          "step": 3,
          "max_logit": 20.875,
          "min_logit": -14.75
        },
        {
          "step": 4,
          "max_logit": 23.75,
          "min_logit": -12.625
        },
        {
          "step": 5,
          "max_logit": 22.375,
          "min_logit": -10.9375
        },
        {
          "step": 6,
          "max_logit": 19.125,
          "min_logit": -15.4375
        },
        {
          "step": 7,
          "max_logit": 23.875,
          "min_logit": -8.375
        },
        {
          "step": 8,
          "max_logit": 24.5,
          "min_logit": -10.6875
        },
        {
          "step": 9,
          "max_logit": 16.75,
          "min_logit": -15.875
        },
        {
          "step": 10,
          "max_logit": 19.125,
          "min_logit": -11.6875
        }
      ],
      "raw_output": "There is no existence of a car in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        1803,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a sandwich in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 80,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 22.75,
          "min_logit": -8.625
        },
        {
          "step": 1,
          "max_logit": 27.0,
          "min_logit": -5.28125
        },
        {
          "step": 2,
          "max_logit": 22.125,
          "min_logit": -10.0625
        },
        {
          "step": 3,
          "max_logit": 28.375,
          "min_logit": -9.9375
        },
        {
          "step": 4,
          "max_logit": 23.875,
          "min_logit": -10.4375
        },
        {
          "step": 5,
          "max_logit": 14.5625,
          "min_logit": -15.5625
        },
        {
          "step": 6,
          "max_logit": 19.0,
          "min_logit": -13.4375
        },
        {
          "step": 7,
          "max_logit": 22.0,
          "min_logit": -10.4375
        },
        {
          "step": 8,
          "max_logit": 15.5,
          "min_logit": -14.625
        },
        {
          "step": 9,
          "max_logit": 21.5,
          "min_logit": -8.0
        },
        {
          "step": 10,
          "max_logit": 24.25,
          "min_logit": -10.8125
        },
        {
          "step": 11,
          "max_logit": 17.25,
          "min_logit": -15.375
        },
        {
          "step": 12,
          "max_logit": 25.625,
          "min_logit": -6.875
        }
      ],
      "raw_output": "Yes, there is a sandwich on the table in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        27874,
        389,
        279,
        1965,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a bowl in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 81,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 24.375,
          "min_logit": -9.5625
        },
        {
          "step": 1,
          "max_logit": 28.25,
          "min_logit": -9.5625
        },
        {
          "step": 2,
          "max_logit": 24.875,
          "min_logit": -10.5625
        },
        {
          "step": 3,
          "max_logit": 20.25,
          "min_logit": -14.0625
        },
        {
          "step": 4,
          "max_logit": 24.0,
          "min_logit": -11.4375
        },
        {
          "step": 5,
          "max_logit": 22.75,
          "min_logit": -9.1875
        },
        {
          "step": 6,
          "max_logit": 19.875,
          "min_logit": -14.3125
        },
        {
          "step": 7,
          "max_logit": 24.75,
          "min_logit": -7.25
        },
        {
          "step": 8,
          "max_logit": 24.375,
          "min_logit": -9.9375
        },
        {
          "step": 9,
          "max_logit": 16.75,
          "min_logit": -16.125
        },
        {
          "step": 10,
          "max_logit": 18.875,
          "min_logit": -12.3125
        }
      ],
      "raw_output": "There is no existence of a bowl in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        19212,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a hot dog in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 82,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.5,
          "min_logit": -8.6875
        },
        {
          "step": 1,
          "max_logit": 27.0,
          "min_logit": -5.21875
        },
        {
          "step": 2,
          "max_logit": 22.125,
          "min_logit": -10.25
        },
        {
          "step": 3,
          "max_logit": 29.125,
          "min_logit": -10.4375
        },
        {
          "step": 4,
          "max_logit": 25.0,
          "min_logit": -10.0625
        },
        {
          "step": 5,
          "max_logit": 16.875,
          "min_logit": -15.75
        },
        {
          "step": 6,
          "max_logit": 23.25,
          "min_logit": -14.4375
        },
        {
          "step": 7,
          "max_logit": 19.25,
          "min_logit": -13.0625
        },
        {
          "step": 8,
          "max_logit": 25.625,
          "min_logit": -9.625
        },
        {
          "step": 9,
          "max_logit": 17.875,
          "min_logit": -14.8125
        },
        {
          "step": 10,
          "max_logit": 23.125,
          "min_logit": -7.6875
        }
      ],
      "raw_output": "Yes, there is a hot dog in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        4017,
        5562,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a handbag in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 83,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 24.0,
          "min_logit": -9.4375
        },
        {
          "step": 1,
          "max_logit": 27.625,
          "min_logit": -9.375
        },
        {
          "step": 2,
          "max_logit": 23.75,
          "min_logit": -9.25
        },
        {
          "step": 3,
          "max_logit": 18.625,
          "min_logit": -14.5
        },
        {
          "step": 4,
          "max_logit": 24.0,
          "min_logit": -11.375
        },
        {
          "step": 5,
          "max_logit": 24.5,
          "min_logit": -9.6875
        },
        {
          "step": 6,
          "max_logit": 21.75,
          "min_logit": -15.75
        },
        {
          "step": 7,
          "max_logit": 26.375,
          "min_logit": -15.0
        },
        {
          "step": 8,
          "max_logit": 24.375,
          "min_logit": -6.4375
        },
        {
          "step": 9,
          "max_logit": 23.625,
          "min_logit": -10.375
        },
        {
          "step": 10,
          "max_logit": 16.5,
          "min_logit": -16.0
        },
        {
          "step": 11,
          "max_logit": 19.0,
          "min_logit": -11.875
        }
      ],
      "raw_output": "There is no existence of a handbag in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        1424,
        21250,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a person in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 84,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.5,
          "min_logit": -9.125
        },
        {
          "step": 1,
          "max_logit": 26.0,
          "min_logit": -4.625
        },
        {
          "step": 2,
          "max_logit": 21.875,
          "min_logit": -11.25
        },
        {
          "step": 3,
          "max_logit": 28.125,
          "min_logit": -8.375
        },
        {
          "step": 4,
          "max_logit": 24.0,
          "min_logit": -9.5625
        },
        {
          "step": 5,
          "max_logit": 16.625,
          "min_logit": -16.75
        },
        {
          "step": 6,
          "max_logit": 18.0,
          "min_logit": -14.75
        },
        {
          "step": 7,
          "max_logit": 25.0,
          "min_logit": -10.5625
        },
        {
          "step": 8,
          "max_logit": 18.375,
          "min_logit": -17.125
        },
        {
          "step": 9,
          "max_logit": 19.875,
          "min_logit": -12.0625
        }
      ],
      "raw_output": "Yes, there is a person in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        1697,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a dining table in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 85,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 26.5,
          "min_logit": -10.125
        },
        {
          "step": 1,
          "max_logit": 28.75,
          "min_logit": -10.0625
        },
        {
          "step": 2,
          "max_logit": 26.125,
          "min_logit": -10.875
        },
        {
          "step": 3,
          "max_logit": 22.375,
          "min_logit": -13.875
        },
        {
          "step": 4,
          "max_logit": 23.125,
          "min_logit": -11.8125
        },
        {
          "step": 5,
          "max_logit": 21.875,
          "min_logit": -9.5
        },
        {
          "step": 6,
          "max_logit": 20.25,
          "min_logit": -14.75
        },
        {
          "step": 7,
          "max_logit": 25.25,
          "min_logit": -14.5625
        },
        {
          "step": 8,
          "max_logit": 25.75,
          "min_logit": -6.9375
        },
        {
          "step": 9,
          "max_logit": 24.875,
          "min_logit": -9.9375
        },
        {
          "step": 10,
          "max_logit": 16.75,
          "min_logit": -16.625
        },
        {
          "step": 11,
          "max_logit": 19.125,
          "min_logit": -11.4375
        }
      ],
      "raw_output": "There is no existence of a dining table in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        17914,
        1965,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a car in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 86,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.125,
          "min_logit": -9.3125
        },
        {
          "step": 1,
          "max_logit": 25.125,
          "min_logit": -9.5625
        },
        {
          "step": 2,
          "max_logit": 17.0,
          "min_logit": -14.4375
        },
        {
          "step": 3,
          "max_logit": 18.25,
          "min_logit": -16.0
        },
        {
          "step": 4,
          "max_logit": 19.875,
          "min_logit": -13.25
        },
        {
          "step": 5,
          "max_logit": 23.5,
          "min_logit": -11.9375
        },
        {
          "step": 6,
          "max_logit": 17.25,
          "min_logit": -16.75
        },
        {
          "step": 7,
          "max_logit": 21.875,
          "min_logit": -9.0
        },
        {
          "step": 8,
          "max_logit": 24.75,
          "min_logit": -9.875
        },
        {
          "step": 9,
          "max_logit": 16.625,
          "min_logit": -18.0
        },
        {
          "step": 10,
          "max_logit": 23.125,
          "min_logit": -5.8125
        }
      ],
      "raw_output": "There are several cars in the background of the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        525,
        3807,
        9331,
        304,
        279,
        4004,
        315,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a truck in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 87,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.875,
          "min_logit": -9.25
        },
        {
          "step": 1,
          "max_logit": 26.875,
          "min_logit": -9.375
        },
        {
          "step": 2,
          "max_logit": 23.0,
          "min_logit": -10.0
        },
        {
          "step": 3,
          "max_logit": 18.75,
          "min_logit": -14.625
        },
        {
          "step": 4,
          "max_logit": 23.125,
          "min_logit": -12.5
        },
        {
          "step": 5,
          "max_logit": 22.375,
          "min_logit": -10.9375
        },
        {
          "step": 6,
          "max_logit": 19.125,
          "min_logit": -16.875
        },
        {
          "step": 7,
          "max_logit": 23.875,
          "min_logit": -7.3125
        },
        {
          "step": 8,
          "max_logit": 23.0,
          "min_logit": -11.25
        },
        {
          "step": 9,
          "max_logit": 15.625,
          "min_logit": -17.375
        },
        {
          "step": 10,
          "max_logit": 19.375,
          "min_logit": -11.75
        }
      ],
      "raw_output": "There is no existence of a truck in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        10855,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a frisbee in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 88,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.875,
          "min_logit": -8.3125
        },
        {
          "step": 1,
          "max_logit": 26.375,
          "min_logit": -5.0
        },
        {
          "step": 2,
          "max_logit": 23.0,
          "min_logit": -9.9375
        },
        {
          "step": 3,
          "max_logit": 29.375,
          "min_logit": -9.875
        },
        {
          "step": 4,
          "max_logit": 26.625,
          "min_logit": -8.6875
        },
        {
          "step": 5,
          "max_logit": 18.0,
          "min_logit": -16.875
        },
        {
          "step": 6,
          "max_logit": 31.25,
          "min_logit": -15.0625
        },
        {
          "step": 7,
          "max_logit": 32.75,
          "min_logit": -14.5
        },
        {
          "step": 8,
          "max_logit": 20.5,
          "min_logit": -14.625
        },
        {
          "step": 9,
          "max_logit": 26.625,
          "min_logit": -11.75
        },
        {
          "step": 10,
          "max_logit": 19.0,
          "min_logit": -17.0
        },
        {
          "step": 11,
          "max_logit": 23.375,
          "min_logit": -9.4375
        }
      ],
      "raw_output": "Yes, there is a frisbee in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        1422,
        285,
        32031,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a dog in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 89,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.125,
          "min_logit": -9.9375
        },
        {
          "step": 1,
          "max_logit": 28.625,
          "min_logit": -9.3125
        },
        {
          "step": 2,
          "max_logit": 25.875,
          "min_logit": -11.375
        },
        {
          "step": 3,
          "max_logit": 21.375,
          "min_logit": -15.0625
        },
        {
          "step": 4,
          "max_logit": 23.875,
          "min_logit": -11.75
        },
        {
          "step": 5,
          "max_logit": 23.625,
          "min_logit": -9.5
        },
        {
          "step": 6,
          "max_logit": 20.625,
          "min_logit": -15.5
        },
        {
          "step": 7,
          "max_logit": 23.375,
          "min_logit": -8.0
        },
        {
          "step": 8,
          "max_logit": 23.875,
          "min_logit": -11.75
        },
        {
          "step": 9,
          "max_logit": 16.0,
          "min_logit": -16.625
        },
        {
          "step": 10,
          "max_logit": 19.0,
          "min_logit": -11.875
        }
      ],
      "raw_output": "There is no existence of a dog in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        5562,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a knife in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 90,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 22.5,
          "min_logit": -8.125
        },
        {
          "step": 1,
          "max_logit": 27.25,
          "min_logit": -4.125
        },
        {
          "step": 2,
          "max_logit": 22.125,
          "min_logit": -9.6875
        },
        {
          "step": 3,
          "max_logit": 28.25,
          "min_logit": -9.125
        },
        {
          "step": 4,
          "max_logit": 24.875,
          "min_logit": -8.6875
        },
        {
          "step": 5,
          "max_logit": 17.25,
          "min_logit": -17.375
        },
        {
          "step": 6,
          "max_logit": 19.125,
          "min_logit": -12.1875
        },
        {
          "step": 7,
          "max_logit": 26.375,
          "min_logit": -9.75
        },
        {
          "step": 8,
          "max_logit": 18.875,
          "min_logit": -15.875
        },
        {
          "step": 9,
          "max_logit": 22.625,
          "min_logit": -9.4375
        }
      ],
      "raw_output": "Yes, there is a knife in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        21430,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a cup in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 91,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 24.75,
          "min_logit": -8.75
        },
        {
          "step": 1,
          "max_logit": 29.0,
          "min_logit": -9.8125
        },
        {
          "step": 2,
          "max_logit": 26.375,
          "min_logit": -9.9375
        },
        {
          "step": 3,
          "max_logit": 20.875,
          "min_logit": -14.4375
        },
        {
          "step": 4,
          "max_logit": 23.5,
          "min_logit": -10.9375
        },
        {
          "step": 5,
          "max_logit": 22.75,
          "min_logit": -10.875
        },
        {
          "step": 6,
          "max_logit": 20.375,
          "min_logit": -15.6875
        },
        {
          "step": 7,
          "max_logit": 24.5,
          "min_logit": -7.34375
        },
        {
          "step": 8,
          "max_logit": 24.625,
          "min_logit": -10.9375
        },
        {
          "step": 9,
          "max_logit": 17.125,
          "min_logit": -15.625
        },
        {
          "step": 10,
          "max_logit": 19.25,
          "min_logit": -11.8125
        },
        {
          "step": 11,
          "max_logit": 24.125,
          "min_logit": -6.59375
        }
      ],
      "raw_output": "There is no existence of a cup in the image description.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        10525,
        304,
        279,
        2168,
        4008,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a person in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 92,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.375,
          "min_logit": -9.1875
        },
        {
          "step": 1,
          "max_logit": 26.625,
          "min_logit": -4.40625
        },
        {
          "step": 2,
          "max_logit": 21.625,
          "min_logit": -10.125
        },
        {
          "step": 3,
          "max_logit": 27.75,
          "min_logit": -7.96875
        },
        {
          "step": 4,
          "max_logit": 23.5,
          "min_logit": -9.25
        },
        {
          "step": 5,
          "max_logit": 16.75,
          "min_logit": -16.0
        },
        {
          "step": 6,
          "max_logit": 18.25,
          "min_logit": -12.0
        },
        {
          "step": 7,
          "max_logit": 24.25,
          "min_logit": -9.625
        },
        {
          "step": 8,
          "max_logit": 18.875,
          "min_logit": -15.4375
        },
        {
          "step": 9,
          "max_logit": 20.5,
          "min_logit": -11.0
        }
      ],
      "raw_output": "Yes, there is a person in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        1697,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a car in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 93,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 24.875,
          "min_logit": -9.5
        },
        {
          "step": 1,
          "max_logit": 28.625,
          "min_logit": -9.625
        },
        {
          "step": 2,
          "max_logit": 26.0,
          "min_logit": -10.5
        },
        {
          "step": 3,
          "max_logit": 19.375,
          "min_logit": -14.9375
        },
        {
          "step": 4,
          "max_logit": 22.75,
          "min_logit": -12.5
        },
        {
          "step": 5,
          "max_logit": 23.0,
          "min_logit": -10.875
        },
        {
          "step": 6,
          "max_logit": 17.25,
          "min_logit": -14.5625
        },
        {
          "step": 7,
          "max_logit": 23.125,
          "min_logit": -7.71875
        },
        {
          "step": 8,
          "max_logit": 24.375,
          "min_logit": -11.25
        },
        {
          "step": 9,
          "max_logit": 16.75,
          "min_logit": -15.625
        },
        {
          "step": 10,
          "max_logit": 18.75,
          "min_logit": -11.875
        },
        {
          "step": 11,
          "max_logit": 21.5,
          "min_logit": -10.8125
        }
      ],
      "raw_output": "There is no existence of any car in the image information.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        894,
        1803,
        304,
        279,
        2168,
        1995,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a cake in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 94,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.875,
          "min_logit": -7.1875
        },
        {
          "step": 1,
          "max_logit": 26.375,
          "min_logit": -4.1875
        },
        {
          "step": 2,
          "max_logit": 22.375,
          "min_logit": -9.5625
        },
        {
          "step": 3,
          "max_logit": 28.5,
          "min_logit": -9.625
        },
        {
          "step": 4,
          "max_logit": 25.25,
          "min_logit": -8.3125
        },
        {
          "step": 5,
          "max_logit": 15.625,
          "min_logit": -15.8125
        },
        {
          "step": 6,
          "max_logit": 20.875,
          "min_logit": -10.4375
        },
        {
          "step": 7,
          "max_logit": 27.125,
          "min_logit": -9.25
        },
        {
          "step": 8,
          "max_logit": 19.75,
          "min_logit": -14.9375
        },
        {
          "step": 9,
          "max_logit": 24.0,
          "min_logit": -7.03125
        }
      ],
      "raw_output": "Yes, there is a cake in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        19145,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a bottle in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 95,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 24.875,
          "min_logit": -8.9375
        },
        {
          "step": 1,
          "max_logit": 29.0,
          "min_logit": -9.5
        },
        {
          "step": 2,
          "max_logit": 26.125,
          "min_logit": -10.375
        },
        {
          "step": 3,
          "max_logit": 21.125,
          "min_logit": -14.375
        },
        {
          "step": 4,
          "max_logit": 23.625,
          "min_logit": -11.3125
        },
        {
          "step": 5,
          "max_logit": 22.25,
          "min_logit": -12.5625
        },
        {
          "step": 6,
          "max_logit": 19.75,
          "min_logit": -16.75
        },
        {
          "step": 7,
          "max_logit": 24.25,
          "min_logit": -7.78125
        },
        {
          "step": 8,
          "max_logit": 24.25,
          "min_logit": -11.125
        },
        {
          "step": 9,
          "max_logit": 16.875,
          "min_logit": -15.75
        },
        {
          "step": 10,
          "max_logit": 19.0,
          "min_logit": -11.75
        },
        {
          "step": 11,
          "max_logit": 21.875,
          "min_logit": -10.1875
        }
      ],
      "raw_output": "There is no existence of a bottle in the image information.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        16486,
        304,
        279,
        2168,
        1995,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a person in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 96,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 23.0,
          "min_logit": -8.25
        },
        {
          "step": 1,
          "max_logit": 26.125,
          "min_logit": -4.53125
        },
        {
          "step": 2,
          "max_logit": 22.5,
          "min_logit": -9.5
        },
        {
          "step": 3,
          "max_logit": 29.125,
          "min_logit": -8.6875
        },
        {
          "step": 4,
          "max_logit": 25.625,
          "min_logit": -8.5625
        },
        {
          "step": 5,
          "max_logit": 17.0,
          "min_logit": -17.125
        },
        {
          "step": 6,
          "max_logit": 21.375,
          "min_logit": -12.375
        },
        {
          "step": 7,
          "max_logit": 27.75,
          "min_logit": -8.6875
        },
        {
          "step": 8,
          "max_logit": 20.5,
          "min_logit": -15.3125
        },
        {
          "step": 9,
          "max_logit": 21.375,
          "min_logit": -11.25
        }
      ],
      "raw_output": "Yes, there is a person in the image.",
      "enforced_output": "Yes",
      "generated_tokens": [
        9454,
        11,
        1052,
        374,
        264,
        1697,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "Yes"
    },
    {
      "prompt": "Is there a car in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 97,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.0,
          "min_logit": -9.25
        },
        {
          "step": 1,
          "max_logit": 28.75,
          "min_logit": -9.5625
        },
        {
          "step": 2,
          "max_logit": 25.375,
          "min_logit": -11.6875
        },
        {
          "step": 3,
          "max_logit": 21.25,
          "min_logit": -15.1875
        },
        {
          "step": 4,
          "max_logit": 23.625,
          "min_logit": -12.125
        },
        {
          "step": 5,
          "max_logit": 23.625,
          "min_logit": -10.8125
        },
        {
          "step": 6,
          "max_logit": 19.875,
          "min_logit": -15.0
        },
        {
          "step": 7,
          "max_logit": 23.75,
          "min_logit": -8.3125
        },
        {
          "step": 8,
          "max_logit": 24.0,
          "min_logit": -10.5625
        },
        {
          "step": 9,
          "max_logit": 16.75,
          "min_logit": -16.125
        },
        {
          "step": 10,
          "max_logit": 18.875,
          "min_logit": -11.625
        }
      ],
      "raw_output": "There is no existence of a car in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        1803,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a remote in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 98,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.875,
          "min_logit": -9.875
        },
        {
          "step": 1,
          "max_logit": 29.125,
          "min_logit": -10.25
        },
        {
          "step": 2,
          "max_logit": 26.25,
          "min_logit": -10.6875
        },
        {
          "step": 3,
          "max_logit": 22.875,
          "min_logit": -14.875
        },
        {
          "step": 4,
          "max_logit": 24.25,
          "min_logit": -11.8125
        },
        {
          "step": 5,
          "max_logit": 22.625,
          "min_logit": -10.8125
        },
        {
          "step": 6,
          "max_logit": 19.875,
          "min_logit": -15.25
        },
        {
          "step": 7,
          "max_logit": 21.5,
          "min_logit": -11.5625
        },
        {
          "step": 8,
          "max_logit": 24.625,
          "min_logit": -9.75
        },
        {
          "step": 9,
          "max_logit": 17.5,
          "min_logit": -16.0
        },
        {
          "step": 10,
          "max_logit": 19.375,
          "min_logit": -11.375
        },
        {
          "step": 11,
          "max_logit": 22.125,
          "min_logit": -9.875
        }
      ],
      "raw_output": "There is no existence of a remote in the image information.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        8699,
        304,
        279,
        2168,
        1995,
        13,
        151645
      ],
      "output_text": "No"
    },
    {
      "prompt": "Is there a tv in the image?",
      "method": {
        "erw": true,
        "pva": true,
        "ven": true,
        "lambda": 0.9,
        "beta": 0.9,
        "alpha": 0.6,
        "ven_eps": 1e-05
      },
      "sample": {
        "dataset_index": 99,
        "hf_repo": "lmms-lab/POPE",
        "hf_subset": "default",
        "cache_dir": "/data/coco"
      },
      "attention_blocks": [
        {
          "layer": 0,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 1,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 2,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 3,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 4,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 5,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 6,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 7,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 8,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 9,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 10,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 11,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 12,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 13,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 14,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 15,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 16,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 17,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 18,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 19,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 20,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 21,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 22,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 23,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 24,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 25,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 26,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": 27,
          "type": "self_attention",
          "num_heads": 12,
          "hidden_size": 1536,
          "note": "Transformer text block"
        },
        {
          "layer": "vision",
          "type": "vision_encoder",
          "num_heads": null,
          "hidden_size": 1536,
          "image_size": null,
          "note": "Vision encoder configuration"
        },
        {
          "layer": "multimodal",
          "type": "cross_attention",
          "num_heads": null,
          "note": "Qwen2-VL multimodal fusion layers (approximate)"
        }
      ],
      "attn_stats": [
        {
          "step": 0,
          "max_logit": 25.125,
          "min_logit": -9.1875
        },
        {
          "step": 1,
          "max_logit": 28.75,
          "min_logit": -10.3125
        },
        {
          "step": 2,
          "max_logit": 25.875,
          "min_logit": -10.9375
        },
        {
          "step": 3,
          "max_logit": 21.0,
          "min_logit": -14.3125
        },
        {
          "step": 4,
          "max_logit": 23.75,
          "min_logit": -11.3125
        },
        {
          "step": 5,
          "max_logit": 22.5,
          "min_logit": -10.375
        },
        {
          "step": 6,
          "max_logit": 17.125,
          "min_logit": -15.0
        },
        {
          "step": 7,
          "max_logit": 21.375,
          "min_logit": -10.9375
        },
        {
          "step": 8,
          "max_logit": 24.125,
          "min_logit": -9.375
        },
        {
          "step": 9,
          "max_logit": 16.625,
          "min_logit": -15.8125
        },
        {
          "step": 10,
          "max_logit": 19.0,
          "min_logit": -11.5
        }
      ],
      "raw_output": "There is no existence of a television in the image.",
      "enforced_output": "No",
      "generated_tokens": [
        3862,
        374,
        902,
        13885,
        315,
        264,
        12425,
        304,
        279,
        2168,
        13,
        151645
      ],
      "output_text": "No"
    }
  ],
  "metrics": {
    "pope_accuracy": 0.78,
    "pope_yes_rate": 0.36,
    "pope_f1": 0.7441860465116279,
    "chair_i": 0.0,
    "chair_s": 0.0
  },
  "delta_vs_baseline": {
    "pope_accuracy": 0.020000000000000018,
    "pope_yes_rate": 0.07999999999999996,
    "pope_f1": 0.051878354203935606,
    "chair_i": 0.0,
    "chair_s": 0.0
  }
}